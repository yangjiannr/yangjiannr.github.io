<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hadoop环境搭载]]></title>
    <url>%2F2017%2F12%2F25%2FHadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[官网安装教程：http://archive.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.13.0/hadoop-project-dist/hadoop-common/SingleCluster.html 环境本教程使用 CentOS 7 64位 作为系统环境，请自行安装系统。装好了 CentOS 系统之后，在安装 Hadoop 前还需要做一些必备工作。 创建hadoop用户如果你安装 CentOS 的时候不是用的 “hadoop” 用户，那么需要增加一个名为 hadoop 的用户。 123456su # 上述提到的以 root 用户登录useradd -m hadoop -s /bin/bash # 创建新用户hadooppasswd hadoop # 修改密码，按提示输入两次密码 visudo 或 vim /etc/sudoers# 找到 root ALL=(ALL) ALL 这行# 然后在这行下面增加一行内容：hadoop ALL=(ALL) ALL （当中的间隔为tab） 免密登录设置12345678910111213sudo yum install sshsudo yum install openssh-clientssudo yum install openssh-server//免密登录ssh-keygen -t rsa//回车回车ll -a //生成了 .ssh文件夹，文件夹内有id_rsa 和 id_rsa.pub 两个文件cp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys//测试是否成功ssh localhost // 无需密码则表示设置成功 关闭防火墙Centos直接 123sudo systemctl stop firewalld.service #停止firewallsudo systemctl disable firewalld.service #禁止firewall开机启动sudo firewall-cmd --state #查看默认防火墙状态（关闭后显示notrunning，开启后显示running） Centos7系统的防火墙放开50070端口 123步骤：1.sudo firewall-cmd --zone=public --add-port=50070/tcp --permanent 2.重启防火墙 sudo firewall-cmd --reload 从本机拷贝文件至远程主机jdk-9.0.1：jdk-9.0.1_linux-x64_bin.tar.gz hadoop-2.6.0-cdh5.7.0.tar.gzhadoop-2.6.0-cdh5.7.0.tar.gz 远程主机（用户名hadoop）： [hadoop@localhost ~]$ mkdir -p app/lib [hadoop@localhost ~]$ mkdir package 本机，将需要的文件远程拷贝到远程主机中 scp jdk-9.0.1_linux-x64_bin.tar.gz hadoop@hadoop:/home/hadoop/package scp hadoop-2.6.0-cdh5.7.0.tar.gz hadoop@hadoop:/home/hadoop/package 安装Java环境远程主机 /home/hadoop/package : tar -zxvf jdk-9.0.1_linux-x64_bin.tar.gz -C ~/app/lib tar -zxvf hadoop-2.6.0-cdh5.7.0.tar.gz -C ../app/lib/ sudo vim /etc/profile 或者 vim ~/.bash_profile尾部添加 123export JAVA_HOME=/home/hadoop/app/lib/jdk-9.0.1export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=&quot;.:$JAVA_HOME/lib:$CLASSPATH&quot; 使配置文件生效 . /etc/profile 或者 source /etc/profile . .~/.bash_profile 或者 source .~/.bash_profile 验证： echo $JAVA_HOME /home/hadoop/app/lib/jdk-9.0.1 java -version 123java version &quot;9.0.1&quot;Java(TM) SE Runtime Environment (build 9.0.1+11)Java HotSpot(TM) 64-Bit Server VM (build 9.0.1+11, mixed mode) Hadoop配置文件的修改 如果是linux系统下则可以 rm -rf .cmd，删除cmd文件[hadoop@localhost hadoop-2.6.0-cdh5.7.0]$ `find . -name ‘.cmd’ -type f -print -exec rm -rf {} \;` 在hadoop_home/etc/hadoop路径下 $ vim hadoop-env.sh找到export JAVA_HOME=${JAVA_HOME}，并且注释掉这一行，添加下面的一行（jdk的根目录） export JAVA_HOME=/home/hadoop/app/lib/jdk-9.0.1 etc/hadoop/core-site.xml: 1234567891011&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/app/tmp&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; etc/hadoop/hdfs-site.xml: 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; sudo vim /etc/profile 或者 vim ~/.bash_profile尾部添加 123456789export HADOOP_HOME=/home/hadoop/app/lib/hadoop-2.6.0-cdh5.7.0export PATH=$HADOOP/bin:$PATHexport HADOOP_INSTALL=$HADOOP_HOMEexport HADOOP_MAPRED_HOME=$HADOOP_HOMEexport HADOOP_COMMON_HOME=$HADOOP_HOMEexport HADOOP_HDFS_HOME=$HADOOP_HOMEexport YARN_HOME=$HADOOP_HOMEexport HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/nativeexport PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin 使配置文件生效 . /etc/profile 或者 source /etc/profile . .~/.bash_profile 或者 source .~/.bash_profile 启动hdfs 格式化文件系统（仅第一次执行即可，不要重复执行）：./bin/hdfs namenode -format ./sbin/start-dfs.sh 可能会出现需要yes, 输入密码 验证是否成功 启动完成后，可以通过命令 jps 来判断是否成功启动，若成功启动则会列出如下进程: “NameNode”、”DataNode”和SecondaryNameNode（如果 SecondaryNameNode 没有启动，请运行 sbin/stop-dfs.sh 关闭进程，然后再次尝试启动尝试）。如果没有 NameNode 或 DataNode ，那就是配置不成功，请仔细检查之前步骤，或通过查看启动日志排查原因。$ jps 1425 NameNode 1702 SecondaryNameNode 1546 DataNode 1855 Jps 浏览器方式验证 http://localhost:50070/ （如果是远程主机则将localhost换成远程主机IP） 停止$ sbin/stop-dfs.sh]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[共识机制]]></title>
    <url>%2F2017%2F11%2F01%2F%E5%85%B1%E8%AF%86%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[区块链要成为一个难以攻破的、公开的、不可篡改数据记录的去中心化诚实可信系统，需要在尽可能短的时间内做到分布式数据记录的安全、明确及不可逆，提供一个最坚实且去中心化的系统。在实践中，该流程分为两个方面： 一是选择一个独特的节点来产生一个区块二是使分布式数据记录不可逆 实现上述流程的技术核心就是：共识机制。共识机制是区块链节点就区块信息达成全网一致共识的机制，可以保证最新区块被准确添加至区块链、节点存储的区块链信息一致不分叉甚至可以抵御恶意攻击。 当前主流的共识机制包括：工作量证明、权益证明、工作量证明与权益证明混合、股份授权证明、瑞波共识协议等。 （一）工作量证明 工作量证明（Proof of Work，PoW），顾名思义，即指工作量的证明。PoW机制的基本步骤如下： 节点监听全网数据记录，通过基本合法性验证的数据记录将进行暂存； 节点消耗自身算力尝试不同的随机数，进行指定哈希计算，并不断重复该过程直至找到合理的随机数； 找到合理的随机数后，生成区块信息，首先输入区块头信息，然后是区块记录信息； 接着对外广播出新产生的区块，其他节点验证通过后，连接至区块链中，主链高度加一，然后所有节点切换至新区块后面继续进行工作量证明的区块产生。 PoW叫工作量证明体现在步骤2中，节点需要不断消耗算力工作，进行哈希计算，以找到期望的随机数。如果两个节点在同一时间找到区块，那么网络将根据后续节点和区块生成情况来确定哪个区块构建最终区块链。 其工作量主要体现在：一个符合要求的区块随机数由N个前导零构成，零的个数取决于网络的难度值。要得到合理的随机数需要经过大量尝试计算，计算时间取决于机器的哈希运算速度。当某个节点提供出一个合理的随机数值，说明该节点确实经过了大量的尝试计算。当然，这并不能得出计算次数的绝对值，因为寻找合理随机数值是一个概率事件。 挖矿有三个重要功能： 发行新的货币 维系系统的支付功能 通过算力保障系统安全 PoW机制存在两个方面明显缺陷： 算力的消耗与浪费。 算力集中化凸显。 （二）权益证明 PoS是一个根据持有货币的量和时间，进行利息分发和区块产生的机制。 币天：每个币每天产生1币天。 如果发现了一个新PoS区块，币天就会被清空为0。每被清空365币天，将会从区块中获得0.05个币的利息（可理解为年利率5%）。 未来币 每个区块链的备份都存放在未来币网络的每个节点里，而且在每个节点上没有加密的每个账户都能够生成区块，只要至少一个新入账户的交易已经确认了1440次。任何账户只要达到了这个标准就会被视为“激活账户”。在未来币里，每个区块都包含着255个交易，每个交易都是由包含识别参数的192字节的数据头开始的。一个区块里的每个交易都是由128个字节所代表着。总共加在一起就意味着最大的区块大小有32K字节。 每个区块都有一个“生成签名”的参数。激活账户用自己的私钥在原先的区块上签署“生成签名”。这就产生了一个64字节的签名，之后通过SHA256散列该签名。哈希产生的前八个字节给出了一个数字，作为一个“hit”。“hit”与目前的目标值相比较，如果计算出的“hit”值要比“目标值”低，那么就可以生成下一个区块了。 对于每个活动账户来讲，“目标值”都是与它自身所确认的余额成比例的。一个持有1000个币的账户得到的目标值是持有20个币账户所得到目标值的50倍。因此，拥有1000个币的持有者产生的区块数是持有20个币的人产生的50倍。同事，“目标值”并不是固定的，随着先前区块的时间戳的流逝时刻都在增长。如果在最初的一秒钟内没有哪个账户的“hit”值是低于“目标值”的，则下一秒钟“目标值”就会翻倍。“目标值”会连续的翻倍，直到一个活动账户的“hit”值有一个较低的数值。还有一个“基本目标”值，它以60秒的间隔设定为目标值。正是这个原因，一个区块平均产生的时间会在60秒。即使在网络上只有很少的激活账户，它们其中的一个最终会产生一个区块，因为“目标”值会变得相当大。通过将你账户的“hit”值与目前的“目标”值相比，你就可以估算出你的“hit”值还有多久能成功。 当一个激活账户赢得产生区块的权利时，就能将任何可获得的且未确认的交易放入区块中，并用所有需要的参数来填充该区块。然后，这个区块就会被传播到网络中作为一个区块链的备选。每一个区块中的负载值、“hit”、产生的账户以及签名都能被网络上接收到它的节点所确认。每个区块参考之前的区块，区块形成的区块链可以用来追溯和查询网络中所有的交易历史，所有这些都会追溯到创世区块。 （三）权益证明+工作量证明 用工作量证明机制PoW发行新币，用权益证明机制PoS维护网络安全，即PoW+PoS机制。该机制中，区块被分成两种形式——PoW区块及PoS区块。在这种新型区块链体系里，区块持有人可以消耗他的币天获得利息，同时获得为网络产生一个区块和用PoS造币的优先权。 在PoW+PoS机制下，只要持有币的人，不论持有的数量多少，都可以挖到数据块，而不用采用任何的矿池导致算力集中。同时，由于多采用币天生成区块，而不是算力，降低了资源消耗，解决了单纯PoW机制在维护网络安全方面先天不足的问题。 （四）股份授权证明 PoS机制使用一个确定性算法以随机选择一个股东来产生下一个区块，该算法中，账户余额决定了节点被选中的可能性。然而，该系统并未使区块链变得越来越安全而不可逆。同时PoS面临的挑战是如何通过及时而高效的方法达成共识。 为达到这个目标，每个持币节点可以将其投票权授予一名代表。获票数最多的前100位代表按既定时间表轮流产生区块。每名代表被分配到一个时间段生产区块。所有代表将收到等同于一个平均水平的区块所含交易费的1%作为报酬。如果一个平均水平的区块含有100股作为交易费，一名代表将获得1股作为报酬，即可大大提高共识效率。这是DPoS的核心思想。 在DPoS中， 第一步是称为一名代表，必须在网络上注册公钥，然后分配一个32位的特有标识符。然后该标识符会被每笔交易数据的“头部”引用。 第二步是授权选票。每个钱包有一个参数设置窗口，在该窗口里用户可以选择一个或更多的代表，并将其分级。一经设定，用户所做的每笔交易将把选票从“输入代表”转移至“输出代表”。 一般情况下，用户不会创建特别以投票为目的的交易，因为那将耗费他们一笔交易费。每个钱包将显示一个状态指示器，让用户知道代表的表现如何。如果某代表错过了太多的区块，那么系统将会推荐用户去换一个新的代表。如果任何代表被发现签发了一个无效的区块，那么所有标准钱包将在每个钱包进行更多交易前要求选出一个新代表。 （五）瑞波共识协议 瑞波共识协议（Ripple Consensus Protocol，RCP），使一组节点能够基于特殊节点列表达成共识。初始特殊节点列表就像一个俱乐部，要接纳一个新成员，必须由一定比例的该俱乐部会员投票通过。 RCP机制的工作原理如下： 验证节点接收存储待验证交易。首先验证节点接收待验证交易，将其存储在本地；其次本轮共识过程中新到的交易需要等待，在下次共识时再确认。 活跃信任节点发送提议：首先，信任节点列表是验证池的一个子集，其信任节点来源于验证池；其次，参与共识过程的信任节点须出于活跃状态，验证节点与信任节点间存在保活机制，长期不活跃节点将被从信任节点列表删除；最后，信任节点根据自身掌握的交易双方额度、交易历史等信息对交易做出判断，并加入到提议中进行发送。 本验证节点检查收到的提议是否来自信任节点列表中的合法信任节点，如果是，则存储；如果不是，则丢弃。 验证节点根据提议确定认可交易列表的步骤如下：首先，令信任节点列表中活跃的信任节点个数为M（比如5个），本轮中交易认可阔值为N（百分比，比如50%），则每一个超过M*N个信任节点认可的交易将被本验证节点认可；其次，本验证节点生成认可交易列表。系统为验证节点设置一个计时器，如果计时器时间已到，本信任节点需要发送自己的认可交易列表。 账本共识达成的步骤如下：首先，本验证节点仍然在接收来自信任节点列表中信任节点的提议，并持续更新认可交易列表；其次，验证节点认可列表的生成并不代表最终账本的形成以及共识的达成，账本共识只有在每笔交易都获得至少超过一定阔值（比如80%）的信任节点列表认可才能达成。如果账本中每笔交易都获得至少超过一定阔值的信任节点列表认可，则共识达成，交易验证结束，否则继续上述过程。 共识过程结束后，已经形成最新的账本，现将上轮剩余的待确认交易以及新交易纳入待确认交易列表，开始新一轮共识过程。 除上述机制外，还有恒星共识协议（Stellar Consensus Protocol，SCP）、改进型使用拜占庭容错机制（Practical Byzantine Fault Tolerance，PBFT）和Pool验证池机制等共识机制被提出，甚至已经应用在区块链系统中，不同共识机制各有其应用场景和优势。 ——《区块链-从数字货币到信用社会》 http://www.frankyang.cn/2017/11/01/consensus/]]></content>
      <categories>
        <category>BlockChain</category>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>BlockChain</tag>
        <tag>Distributed</tag>
        <tag>Consensus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[比特币交易本质--UTXO(Unspent Transaction Output)]]></title>
    <url>%2F2017%2F10%2F02%2F%E6%AF%94%E7%89%B9%E5%B8%81%E4%BA%A4%E6%98%93%E6%9C%AC%E8%B4%A8--UTXO(Unspent%20Transaction%20Output)%2F</url>
    <content type="text"><![CDATA[UTXO 代表 Unspent Transaction Output。 Transaction 被简称为 TX，所以上面这个短语缩写为 UTXO。 现在的银行也好、信用卡也好、证券交易系统也好，互联网第三方支付系统也好，其核心都是基于账户（account based）的设计，由关系数据库支撑。 数据库要确保两点，第一是你要确保业务规则得到遵守，张三的余额充足。第二是确保事务性，也就是原子性、一致性、隔离性、持久性（ACID）。这种基于账户的设计，简单直观，而且在 IT 系统设计里用了几十年，应该说没有什么问题。 我们假设一个这样的场景：张三挖到12.5 枚比特币。过了几天，他把其中 2.5 枚支付给李四。又过了几天，他和李四各出资 2.5 比特币凑成 5 比特币付给王五。 如果是基于账户的设计，张、李、王三人在数据库中各有一个账户，则他们三人的账户变化如下图所示： 但在比特币中，这个过程是通过 UTXO 实现的，图示如下： 比特币的区块链账本里记录的是一笔又一笔的交易。 每笔交易都有若干交易输入，也就是资金来源，也都有若干笔交易输出，也就是资金去向。一般来说，每一笔交易都要花费（spend）一笔输入，产生一笔输出，而其所产生的输出，就是“未花费过的交易输出”，也就是 UTXO。 比特币交易遵守几个规则： 除了 coinbase 交易之外，所有的资金来源都必须来自前面某一个或者几个交易的 UTXO，就像接水管一样，一个接一个，此出彼入，此入彼出，生生不息，钱就在交易之间流动起来了。 任何一笔交易的交易输入总量必须等于交易输出总量，等式两边必须配平。 上图第一个交易#1001号交易是coinbase交易。比特币是矿工挖出来的。当一个矿机费尽九牛二虎之力找到一个合格的区块之后，它就获得一个特权，能够创造一个coinbase交易，在其中放入一笔新钱，并且在交易输出的收款人地址一栏，堂堂正正的写上自己的地址。这个coinbase交易随着张三挖出来的区块被各个节点接受，经过六个确认以后永远的烙印在历史中。 过了几天，张三打算付2.5个比特币给李四，张三就发起一#2001号交易，这个交易的资金来源项写着“#1001(1)”，也就是#1001号交易——张三挖出矿的那个coinbase交易——的第一项UTXO。然后在本交易的交易输出UTXO项中，把2.5个比特币的收款人地址设为李四的地址。 请注意，这一笔交易必须将前面产生那一项12.5个比特币的输出项全部消耗，而由于张三只打算付给李四2.5个比特币，为了要消耗剩下的10比特币，他只好把剩余的那10个比特币支付给自己，这样才能符合输入与输出配平的规则。 再过几天，张三和李四打算AA制合起来给王五付5枚比特币。那么张三或李四发起#3001号交易，在交易输入部分，有两个资金来源，分别是#2001(1)和#2001(2)，代表第#2001号交易的第(1)和第(2)项 UTXO。然后在这个交易的输出部分里如法炮制，给王五5比特币，把张三剩下的7.5比特币发还给自己。以后王五若要再花他这5比特币，就必须在他的交易里注明资金的来源是#3001(1)。 所以，其实并没有什么比特币，只有UTXO。当我们说张三拥有10枚比特币的时候，我实际上是说，当前区块链账本中，有若干笔交易的UTXO项收款人写的是张三的地址，而这些UTX 项的数额总和是10。因为在比特币系统里，一个人可以拥有的地址资源，可谓取之不尽用之不竭。要知道自己的一大堆地址里一共收了多少UTXO，人是算不过来的，需要由比特币钱包代为跟踪计算。 如果采用基于账户的方案，需要一个数据库。这个数据库能够让你很方便的查到张三、李四各自的账户余额。 而 UTXO 方案当然也需要一个数据库，这个数据库记录着当前系统里每一笔“没有花出去的交易输出”，也是就比特币。当节点接收到一笔交易的时候，它需要去 UTXO 数据库里查，看看这笔交易所引用的 UTXO 是否存在，它的收款人（拥有者）是不是当前新交易的付款者。而交易结束之后，数据库要做相应的更新。 首先要明确，无论是账户数据库还是 UTXO 数据库，必须是分散的，每结点一个克隆，一定不能是中心化的。如果比特币系统有一个中心数据库，不管你有多少节点，每一笔交易都要跑去中心数据库验证一下、然后再执行“转账”的事务操作，那就完全谈不上“去中心化”，比特币就毫无价值了，不如老老实实用支付宝。 长期来看，账户数据库会无限膨胀，而UTXO 数据库体积会小很多。 比特币是个匿名体系，它的账户就是“地址”。每一个比特币用户可以拥有几乎无限多的地址，在比特币系统来看，它完全不知道两个地址背后对应的是不是同一个人。 在版本控制方面的考虑，svn 是中心化的数据库保持一份账本，这和区块链的设计自然是相违背的，git 是去中心化的数据库，但会保存太多冗余数据，对于分布式性能肯定是要大打折扣。UTXO数据库是抛弃了历史包袱的git， 只存储了最后一个版本。简易实用。 UTXO具有天然的匿名效果，一个账户所对应的未花费交易是难以发现的。 在性能方面，由于UTXO是独立的数据记录，那么就存在极大的并行性可以提升区块链交易验证速度。 http://www.frankyang.cn/2017/09/30/utxo/]]></content>
      <categories>
        <category>BlockChain</category>
      </categories>
      <tags>
        <tag>BlockChain</tag>
        <tag>BitCoin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2PC&3PC]]></title>
    <url>%2F2017%2F09%2F11%2F2PC%263PC%2F</url>
    <content type="text"><![CDATA[2PC用于保证跨多个节点操作的原子性，也就是说，跨多个节点的操作要么在所有节点上全部执行成功，要么全部失败。Paxos协议用于确保多个节点对某个投票（例如哪个节点为主节点）达成一致。 在分布式系统中，每一个机器节点虽然都能够明确地知道自己在进行实物操作过程中的结果是成功或失败，但却无法直接获取到其他分布式节点的操作结果。为了保持实物处理的ACID特性，就需要引入一个称为“协调者（Coordinator）”的组件来统一调度所有分布式节点的执行逻辑，这些被调度的分布式节点则被称为“参与者（Participant）”。协调者负责调度参与者的行为，并最终决定这些参与者是否要把事务真正进行提交。 2PC（Two-Phase Commit） 二阶段提交，是一种一致性协议，用来保证分布式系统数据的一致性。绝大多数的关系型数据库都是采用二阶段提交协议来完成分布式事务处理的，利用该协议能够非常方便地完成所有分布式事务参与者的协调，统一决定事务的提交或回滚，从而能够有效的保证分布式数据一致性。 阶段一：提交事务请求 事务询问 协调者向所有参与者发送事务内容，询问是否可以执行事务提交操作，并开始等待各参与者的响应。 执行事务 各参与者结点执行事务操作，并将Undo和Redo信息记入事务日志中。 各参与者向协调者反馈事务询问的响应 如果参与者成功执行了事务操作，那么就反馈给协调者Yes响应，表示事务可以执行；如果参与者没有成功执行事务，那么就反馈给协调者No响应，表示事务不可以执行。 由于上面讲述的内容在形式上近似是协调者组织各参与者对一次事务曹组的投票表态过程，因此二阶段提交协议的阶段一也被称为“投票阶段”，即各参与者投票表明是否要继续执行接下去的事务提交操作。 阶段二：执行事务提交可能一：执行事务提交 假如协调者从所有的参与者获得的反馈都是Yes响应，那么就会执行事务提交。 1. 发送提交请求 协调者向所有参与者节点发出Commit请求 2. 事务提交 参与者接收到Commit请求后，会正式执行事务提交操作，并在完成提交之后释放在整个事务执行期间占用的事务资源。 3. 反馈事务提交结果 参与者在完成事务提交之后，向协调者发送Ack消息 4. 完成事务 协调者接收到所有参与者反馈的Ack消息后，完成事务 可能二：中断事务 假如任何一个参与者向协调者反馈了No响应，或者在等待超时之后，协调者尚无法接收到所有参与者的反馈响应，那么就会中断事务。 1. 发送回滚请求 协调者向所有参与者节点发出Rollback请求 2. 事务回滚 参与者接收到Rollback请求后，会利用其再阶段一中记录的Undo信息执行事务回滚操作，并在完成回滚之后释放在整个事务执行期间占用的资源。 3. 反馈事务回滚结果 参与者在完成事务回滚之后，向协调者发送Ack消息 4. 中断事务 协调者接收到所有参与者反馈的Ack消息后，完成事务中断 简单地讲，二阶段提交讲一个事务的处理过程分成了投票和执行两个阶段，其核心是对每个事务都采用先尝试后提交的处理方式。 优缺点二阶段提交协议的优点：原理简单、实现方便二阶段提交协议的缺点：同步阻塞、单点问题、脑裂、太过保守同步阻塞 执行过程中，所有参与该事务操作的逻辑都处于阻塞状态，也就是说，各个参与者在等待其他参与者响应的过程中，将无法进行其他任何操作。 单点问题 协调者的角色在整个二阶段提交协议中起到了非常重要的作用。一旦协调者出现问题，那么整个二阶段提交流程无法运转，更为严重的是，如果协调者是在阶段二中出现问题的话，那么其他参与者将会一直处于锁定事务资源的状态中，而无法继续完成事务操作。 数据不一致 在二阶段提交协议的阶段二，即执行事务提交的时候，当协调者向所有的参与者发送Commit请求之后，发生了局部网络异常或者是协调者在尚未发送完Commit请求之前自身发生了崩溃，导师最终只有部分参与者收到了Commit请求，于是，这部分收到了Commit请求的参与者就会进行事务的提交，而其他没有收到Commit请求的参与者则无法进行事务提交，于是整个分布式系统便出现了数据不一致性现象。 太过保守 二阶段提交协议没有涉及较为完善的容错机制，任意一个节点的失败都会导致整个事务的失败。 二阶段无法解决的问题：协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。 3PC（Three-Phase Commit） 三阶段提交，是2PC的改进版，其将二阶段提交协议的“提交事务请求”过程一分为二，形成了由CanCommit、PreCommit和DoCommit三个阶段组成的视乎处理协议。 三个阶段阶段一：CanCommit 事务询问 协调者向所有的参与者发送一个包含事务内容的CanCommit请求，询问是否可以执行事务提交操作，并开始等待各参与者的响应。 各参与者向协调者反馈事务询问的响应 参与者在接收到来自协调者的CanCommit请求后，正常情况下，如果其自身认为可以顺利执行事务，那么会反馈Yes响应，并进入准备状态，否则反馈No响应。 阶段二：PreCommit在阶段二中，协调者会根据各参与者的反馈情况来决定是否可以进行事务的PreCommit操作，正常情况下，包含两种可能：执行事务预提交 假如协调者从所有参与者获得的反馈都是Yes响应，那么就会执行事务预提交 发送预提交请求 协调者向所有参与者节点发出PreCommit的请求，并进入Prepared阶段。 事务预提交 参与者接收到PreCommit请求后，会执行事务操作，并将Undo和Redo信息记录到事务日志中 各参与者向协调者反馈事务执行的响应 如果参与者成功执行了事务操作，那么就会反馈给协调者Ack响应，同时等待最终的指令：提交（commit）或终止（abort） 中断事务 假如任何一个参与者向协调者反馈了No响应，或者在等待超市之后，协调者尚无法接受所有参与者的反馈响应，那么就会中断事务。 发送中断请求 协调者向所有参与者节点发出abort请求 中断事务 无论是收到来自协调者的abort请求，或者是在等待协调者请求过程中超时，参与者都会中断事务。 阶段三：DoCommit该阶段将进行真正的事务提交，会存在以下两种情况：提交阶段 发送提交请求 事务提交 反馈事务提交结果 完成事务 中断事务进入这一阶段，假设协调者处于正常工作状态，并且有任意一个参与者向协调者反馈了No响应，或者在等待超时之后，协调者尚无法接收到所有参与者的反馈响应，那么就会中断事务 发送中断请求 事务回滚 反馈事务回滚结果 中断事务 需要注意的是，一旦进入阶段三，可能会存在以下两种故障： 协调者出现问题 协调者和参与者之间的网络出现故障 无论出现哪种情况，最终都会导致参与者无法及时接收到来自协调者的DoCommit或者abort请求，针对这样的异常情况，参与者都会在等待超时之后，继续进行事务提交。 三阶段提交协议优缺点 优点：相较于二阶段提交协议，三阶段提交协议最大的优点就是降低了参与者的阻塞范围，并且能够在出现单点故障后继续达成一致。 缺点： 在参与者接收到PreCommit消息后，如果网络出现分区，此时协调者所在的节点和参与者无法进行正常的网络通信，在这种情况下，该参与者依然会进行事务的提交，这必然出现数据的不一致性。 在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者rebort请求时，会在等待超时之后，会继续进行事务的提交。所以，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。 相对于2PC，3PC主要解决的单点故障问题，并减少阻塞，因为一旦参与者无法及时收到来自协调者的信息之后，他会默认执行commit。而不会一直持有事务资源并处于阻塞状态。但是这种机制也会导致数据一致性问题，因为，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。 当协调者和参与者都挂的时候： 第二阶段协调者和参与者挂了，挂了的这个参与者在挂之前已经执行了操作。但是由于他挂了，没有人知道他执行了什么操作。 这种情况下，当新的协调者被选出来之后，他同样是询问所有的参与者的情况来觉得是commit还是roolback。这看上去和二阶段提交一样啊？他是怎么解决一致性问题的呢？ 看上去和二阶段提交的那种数据不一致的情况的现象是一样的，但仔细分析所有参与者的状态的话就会发现其实并不一样。我们假设挂掉的那台参与者执行的操作是commit。那么其他没挂的操作者的状态应该是什么？他们的状态要么是prepare-commit要么是commit。因为3PC的第三阶段一旦有机器执行了commit，那必然第一阶段大家都是同意commit。所以，这时，新选举出来的协调者一旦发现未挂掉的参与者中有人处于commit状态或者是prepare-commit的话，那就执行commit操作。否则就执行rollback操作。这样挂掉的参与者恢复之后就能和其他机器保持数据一致性了。（为了简单的让大家理解，笔者这里简化了新选举出来的协调者执行操作的具体细节，真实情况比我描述的要复杂） 简单概括一下就是，如果挂掉的那台机器已经执行了commit，那么协调者可以从所有未挂掉的参与者的状态中分析出来，并执行commit。如果挂掉的那个参与者执行了rollback，那么协调者和其他的参与者执行的肯定也是rollback操作。 所以，再多引入一个阶段之后，3PC解决了2PC中存在的那种由于协调者和参与者同时挂掉有可能导致的数据一致性问题。]]></content>
      <categories>
        <category>BlockChain</category>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>BlockChain</tag>
        <tag>Distributed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Paxos发展、算法原理]]></title>
    <url>%2F2017%2F09%2F11%2FPaxos%E5%8F%91%E5%B1%95%E3%80%81%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Paxos发展史 Leslie Lamport所提出的Paxos算法是现代分布式系统中的一项重要的基础性技术，得到广泛的应用。 Paxos的整个发展过程大概可以分为三个阶段： 第一阶段：萌芽期，大致是1988-1996年。Liskov等人在PODC上发表了Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems ，提出了一个在副本出现宕机情况下仍能正常工作的主从备份算法，该算法与Paxos在本质上是一致的(The ABCD’s of Paxos)。 第二阶段：1996-2007年。涌现出一批Paxos的不同版本，这些Paxos的变种从不同侧面完善了基础Paxos算法，提升其性能。Liskov等人在1999年提出了PBFT（实用的拜占庭容错算法），这实际上也是Paxos的一个变种，被Lampson称为Byzantine Paxos，该算法对基础Paxos进行了改进，使其可以处理拜占庭错误。 拜占庭将军问题（Byzantine failures），是由莱斯利·兰伯特提出的点对点通信中的基本问题。含义是在存在消息丢失的不可靠信道上试图通过消息传递的方式达到一致性是不可能的。 拜占庭位于如今的土耳其的伊斯坦布尔，是东罗马帝国的首都。由于当时拜占庭罗马帝国国土辽阔，为了防御目的，因此每个军队都分隔很远，将军与将军之间只能靠信差传消息。 在战争的时候，拜占庭军队内所有将军和副官必需达成一致的共识，决定是否有赢的机会才去攻打敌人的阵营。但是，在军队内有可能存有叛徒和敌军的间谍，左右将军们的决定又扰乱整体军队的秩序。在进行共识时，结果并不代表大多数人的意见。这时候，在已知有成员谋反的情况下，其余忠诚的将军在不受叛徒的影响下如何达成一致的协议，拜占庭问题就此形成。 拜占庭假设是对现实世界的模型化，由于硬件错误、网络拥塞或断开以及遭到恶意攻击，计算机和网络可能出现不可预料的行为。拜占庭容错协议必须处理这些失效，并且这些协议还要满足所要解决的问题要求的规范。 Eli Gafni 和 Lamport 在2000年提出了Disk Paxos，这可以认为是Paxos基于磁盘的版本，以支持持久化。 第三阶段：本阶段。Paxos开始在工业界得到了广泛应用。从2006年开始，谷歌公司有两篇影响深远的论文发表在OSDI上，一篇是“Bigtable:A Distributed Storage System for Structured Data”，另一篇“The Chubby lock service for loosely-coupled distributed systems”。两篇论文可以说是揭开了大数据管理的序幕，而Paxos则在大数据管理的核心技术（容错）中扮演了极为重要的角色。 算法原理 Paxos算法维基百科https://en.wikipedia.org/wiki/Paxos_(computer_science)) Paxos算法是基于消息传递且具有高度容错特性的一致性算法，是目前公认的解决分布式一致性问题最有效的算法之一。然而，Paxos算法也因为晦涩难懂而臭名昭著。 Paxos算法的目标就是要保证最终有一个提案会被选定，当提案被选定后，进程最终也能获取到被选定的提案。 问题产生的背景 在常见的分布式系统中，总会发生诸如机器宕机或网络异常（包括消息的延迟、丢失、重复、乱序，还有网络分区）等情况。Paxos算法需要解决的问题就是如何在一个可能发生上述异常的分布式系统中，快速且正确地在集群内部对某个数据的值达成一致，并且保证不论发生以上任何异常，都不会破坏整个系统的一致性。 相关概念在Paxos算法中，有四种角色： Client：产生议题者 Proposer ：提议者 Acceptor(Voters)：决策者（投票者） Learner：最终决策学习者，也就是执行者。 一个进程可能充当不止一种角色。上面4种角色中，提议者和决策者是很重要的，其他的2个角色在整个算法中应该算做打酱油的，Proposer就像Client的使者，由Proposer使者拿着Client的议题去向Acceptor提议，让Acceptor来决策。 Proposer拿着Client的议题去向Acceptor提议，让Acceptor来决策。 Proposer提出议题，Acceptor初步接受或者Acceptor初步不接受。 Acceptor初步接受则Proposer再次向Acceptor确认是否最终接受。 Acceptor最终接受或者Acceptor最终不接受。 Learner最终学习的目标是向所有Acceptor学习，如果有多数派个Acceptor最终接受了某提议，那就得到了最终的结果，算法的目的就达到了。 问题描述 假设有一组可以提出（propose）value（value在提案Proposal里）的进程集合。一个一致性算法需要保证提出的这么多value中： 只有一个value被选定（chosen） 如果没有value被提出，就不应该有value被选定 如果一个value被选定，那么所有进程都应该能学习（learn）到这个被选定的value。 对于一致性算法，安全性（safaty）要求如下： 只有被提出的value才能被选定。 只有一个value被选定，并且 如果某个进程认为某个value被选定了，那么这个value必须是真的被选定的那个。 Paxos的目标：保证最终有一个value会被选定，当value被选定后，进程最终也能获取到被选定的value。 每个参与者以任意的速度执行，可能会因为出错而停止，也可能会重启。同时，即使一个提案被选定后，所有的参与者也都有可能失败或重启，因此除非那些失败或重启的参与者可以记录某些信息，否则将无法确定最终的值。 消息在传输过程中可能会出现不可预知的延迟，也可能会重复或丢失，但是消息不会损坏，即消息内容不会被篡改（拜占庭式的问题）。 算法描述Paxos算法分为两个阶段。具体如下：阶段一：(a) Proposer选择一个提案编号N，然后向半数以上的Acceptor发送编号为N的Prepare请求。 (b) 如果一个Acceptor收到一个编号为N的Prepare请求，且N大于该Acceptor已经响应过的所有Prepare请求的编号，那么它就会将它已经接受过的编号最大的提案（如果有的话）作为响应反馈给Proposer，同时该Acceptor承诺不再接受任何编号小于N的提案。 阶段二：(a) 如果Proposer收到半数以上Acceptor对其发出的编号为N的Prepare请求的响应，那么它就会发送一个针对[N,V]提案的Accept请求给半数以上的Acceptor。注意：V就是收到的响应中编号最大的提案的value，如果响应中不包含任何提案，那么V就由Proposer自己决定。 (b) 如果Acceptor收到一个针对编号为N的提案的Accept请求，只要该Acceptor没有对编号大于N的Prepare请求做出过响应，它就接受该提案。 eg. Learner学习被选定的valueLearner学习（获取）被选定的value有如下三种方案：]]></content>
      <categories>
        <category>BlockChain</category>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Paxos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAP定理(原则)以及BASE理论]]></title>
    <url>%2F2017%2F09%2F05%2FCAP%E5%AE%9A%E7%90%86(%E5%8E%9F%E5%88%99)%E4%BB%A5%E5%8F%8ABASE%E7%90%86%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[#CAP定理(原则)以及BASE理论 CAP定理(原则)概念 CAP原则又称CAP定理，指的是在一个分布式系统中， Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可得兼。 1. 数据一致性(consistency) 一致性（C）：在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本） 在分布式系统中，如果能够做到针对一个数据项的更新操作执行成功后，所有的用户都可以读到其最新的值，那么这样的系统就被认为具有强一致性（严格的一致性）。 2. 服务可用性(availability) 可用性（A）：系统提供的服务必须一致出于可用的状态，对于用户的每一个请求总是能够有限的时间内返回结果。 在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（对数据更新具备高可用性） 3. 分区容错性(partition-tolerance) 分区容忍性（P）：在网络分区的情况下，被分隔的节点仍能正常对外服务 由于当前的网络硬件肯定会出现延迟丢包等问题，所以分区容忍性是我们必须需要实现的。 以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。 一个分布式系统里面，节点组成的网络本来应该是连通的。然而可能因为一些故障，使得有些节点之间不连通了，整个网络就分成了几块区域。数据就散布在了这些不连通的区域中。这就叫分区。 当你一个数据项只在一个节点中保存，那么分区出现后，和这个节点不连通的部分就访问不到这个数据了。这时分区就是无法容忍的。 提高分区容忍性的办法就是一个数据项复制到多个节点上，那么出现分区之后，这一数据项就可能分布到各个区里。容忍性就提高了。然而，要把数据复制到多个节点，就会带来一致性的问题，就是多个节点上面的数据可能是不一致的。要保证一致，每次写操作就都要等待全部节点写成功，而这等待又会带来可用性的问题。 总的来说就是，数据存在的节点越多，分区容忍性越高，但要复制更新的数据就越多，一致性就越难保证。为了保证一致性，更新所有节点数据所需要的时间就越长，可用性就会降低。 根据定理，分布式系统只能满足三项中的两项而不可能满足全部三项。 理解CAP理论的最简单方式是想象两个节点分处分区两侧。 允许至少一个节点更新状态会导致数据不一致，即丧失了C性质。 如果为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了A性质。 除非两个节点可以互相通信，才能既保证C又保证A，这又会导致丧失P性质。 放弃CAP定理 说明 放弃P 如果希望能够避免系统出现分区容错性问题，一种较为简单地做法是将所有的数据（或者仅仅是那些与事务相关的数据）都放在一个分布式节点上。这样的做法虽然无法100%地保证系统不会出错，但至少不会碰到由于网络分区带来的负面影响。但同时需要注意的是，放弃P的同时也就意味着放弃了系统的可扩展性。 放弃A 相对于放弃“分区容错性”来说，放弃可用性则正好相反，其做法是一旦系统遇到网络分区或其他故障时，那么收到影响的服务需要等待一定的时间，因此在等待期间系统无法对外提供正常的服务，即不可用。 放弃C 这里所说的放弃一致性，并不是完全不需要数据一致性，而是放弃数据的强一致性，而保留数据的最终一致性。这样的系统无法保证数据保持实时的一致性，但是能够承诺的是，数据最终会达到一个一致的状态。这里就引入了一个时间窗口的概念，具体多久能够达到数据一致取决于系统的设计，主要包括数据副本在不同节点之间的复制时间长短。 CA非0/1的选择 P 是必选项，那3选2的选择题不就变成数据一致性(consistency)、服务可用性(availability) 2选1？工程实践中一致性有不同程度，可用性也有不同等级，在保证分区容错性的前提下，放宽约束后可以兼顾一致性和可用性，两者不是非此即彼。 CAP定理证明中的一致性指强一致性，强一致性要求多节点组成的被调要能像单节点一样运作、操作具备原子性，数据在时间、时序上都有要求。如果放宽这些要求，还有其他一致性类型： 序列一致性(sequential consistency)：不要求时序一致，A操作先于B操作，在B操作后如果所有调用端读操作得到A操作的结果，满足序列一致性 最终一致性(eventual consistency)：放宽对时间的要求，在被调完成操作响应后的某个时间点，被调多个节点的数据最终达成一致 可用性在CAP定理里指所有读写操作必须要能终止，实际应用中从主调、被调两个不同的视角，可用性具有不同的含义。当P(网络分区)出现时，主调可以只支持读操作，通过牺牲部分可用性达成数据一致。 工程实践中，较常见的做法是通过异步拷贝副本(asynchronous replication)、quorum/NRW，实现在调用端看来数据强一致、被调端最终一致，在调用端看来服务可用、被调端允许部分节点不可用(或被网络分隔)的效果。 延时(latency)，它是衡量系统可用性、与用户体验直接相关的一项重要指标[16]。CAP理论中的可用性要求操作能终止、不无休止地进行，除此之外，我们还关心到底需要多长时间能结束操作，这就是延时，它值得我们设计、实现分布式系统时单列出来考虑。 延时与数据一致性也是一对“冤家”，如果要达到强一致性、多个副本数据一致，必然增加延时。加上延时的考量，我们得到一个CAP理论的修改版本PACELC：如果出现P(网络分区)，如何在A(服务可用性)、C(数据一致性)之间选择；否则，如何在L(延时)、C(数据一致性)之间选择。 CAP原理实例推导 以数据库为例，讨论一下CAP原理: 单实例 一种最简单的情况：”单数据库实例”。 这也是最常见的小站点、个人博客、小论坛的架构。 可以很容易分析出来，由于单实例，所以不存在“网络分区”、“不一致”， 但单点故障后会导致整个数据库瘫痪，所以可用性不能保证。 这就是CAP定理中的，保证”C”和”P”，舍弃”A”。 所有单机版的系统都属于这个范畴，例如MySQL、memcached、redis。 分片Sharding 为了提升可用性，我们在实际生产环境下经常会在客户端应用一些哈希算法，进行数据分片存放，如下图所示： 由于数据是分片存储在每个数据库中，所以依旧能保证数据一致性。由于数据库之间没有互相通信，并不依赖彼此的存在，所以分区可容忍性依旧没有破坏。那么可用性呢？很多时候会有人直接拍脑袋，这里我们用数学的方式来解答这个问题。 假设，集群有两台服务器，数据分布均匀，我们数据库实例宕机的概率是p。 那么这种利用哈希进行数据分片的集群的可用性为：0.5*p*(1-p) + 0.5*p*(1-p) + 1*p*p = p 即使，数据分布均匀或者集群数量增大，结果也是一样的：“集群可用性依旧为p”。 那我们折腾了半天，CAP和单机竟然是一样的，这种情况下CAP各项指标虽然没有提升，但好处是： 单个服务器宕机只会导致服务降级； 集群有了扩容缩容的可能性，这就叫做scalability。 这种分布式的方式常用于：分布式memcached、redis、传统的数据库Sharding、BigTable (列存储式数据库)、Hypertable (列存储式数据库)、HBase (列存储式数据库)、MongoDB (文档式数据库)、Terrastore (文档式数据库)、Redis (KV数据库)、Scalaris (KV数据库)、MemcacheDB (KV数据库)、Berkeley DB (KV数据库) 多副本写入 Client多副本写入，就是Client在写数据库的时候对多个数据库进行写入，并且在两个都写入成功后才认为成功。 由于数据存在多个副本，这种方式会大大的提高读取的可用性。但由于写入的时候要多写， 副本所在的所有实例都必须可用才能成功。所以写入的可用性反而下降了。 假设单机数据库的故障率为p（p&lt;1.0），那么单机数据库的可用性为1-p。 总结就是： 在写入的场景下，一致性( C )和分区可容忍性( P )没有变化，可用性( A )反而有所下降， 从1-p降低到1-2p-p² 在读取的场景下，一致性( C )和分区可容忍性( P )依旧没有变化，可用性( A )有所上升， 从1-p上升到1-p² “Client多副本写入”这种写入方式非常适合于在”读多写少”的场景下提高可用性。 为了改善写入时糟糕的可用性，这种方式还有一些“变种”，例如： 写成功部分副本就返回成功，剩下的副本写入不保证结果。这样做的结果就是牺牲一定的一致性( C )，换取可用性( A )的提升。 总的来说，这种方式属于广义的”Sharding”的范畴，除去上述的缺点还有一个较大的问题就是： 假设副本数为n，Client写入单实例的耗时为t，多副本写入的耗时就是n*t；当n &gt; 1的时候会成倍的影响Client的写入性能。 集群Clustering 为了解决Client写入慢调用复杂等问题，我们引入了集群方案，也就是Clustering。 Clustering和Sharding对比如下： 多副本模式1： 我们可以看到，由于多个副本写入成功才返回，这种方式一致性( C )依旧是保证的。 但写入可用性( A )和分区可容忍性( P )相对于单机均会下降。换来的是： 较为简单的API，客户端不用关注“多写”问题； 读取操作的高可用(HA)。 由于上述方案是强一致性( C )的，这种应用场景常见于金融系统，这种这方面典型的代表有：ZooKeeper (KV数据库)、Vertica (列存储式数据库)、Aster Data (关系型数据库)、Greenplum (关系型数据库) 多副本模式2： 类似”Sharding”中我们采用的方案，生产环境线上的数据库也往往采用放弃一定的一致性( C ) ，来提高可用性( A )和分区可容忍性( P )。 可以看到，由于大多数互联网公司的需求不是要求强一致性( C )， 所以通过放弃一致性，达到更高的可用性( A )和分区可容忍性 ( P )成了目前市面上大多数NoSQL数据库的核心思想。 在Amazon著名的分布式数据库Dynamo中，就是采用类似的方法：”3副本，写入2个成功后就返回成功，剩下的1个副本后续再进行同步”，我们称这种模式叫”最终一致性”。 这方面典型的代表还有：Dynamo (KV数据库)、Voldemort (KV数据库)、Tokyo Cabinet (KV数据库)、KAI (KV数据库)、Cassandra (列存储式数据库)、CouchDB (文档式数据库)、SimpleDB (文档式数据库)、Riak (文档式数据库)、MooseFS (类GFS分布式文件系统) 我们可以看到，系统设计就像穷人家的被子，盖住头和左脚就露出右脚，盖住头和右脚就露出左脚…… 即使你再有钱也不可能将CAP同时100%满足。 我们可以通过用更高可靠性的服务器、更可靠的网络设备达到CAP同时提升。 BASE理论概念 BASE是Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性）三个短语的简写，BASE是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网系统分布式实践的结论，是基于CAP定理逐步演化而来的，其核心思想是即使无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。 Basically Availble –基本可用 支持分区失败（Sharding碎片划分数据库），出了问题服务仅降级（部分不可用）。 基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性——但请注意，这绝不等价于系统不可用，以下两个就是“基本可用”的典型例子： 响应时间上的损失：正常情况下，一个在线搜索引擎需要0.5秒内返回给用户相应的查询结果，但由于出现异常（比如系统部分机房发生断电或断网故障），查询结果的响应时间增加到了1~2秒。 功能上的损失：正常情况下，在一个电子商务网站上进行购物，消费者几乎能够顺利地完成每一笔订单，但是在一些节日大促购物高峰的时候，由于消费者的购物行为激增，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。 Soft-state –软状态/柔性 事务”Soft state” 可以理解为”无连接”的, 而 “Hard state” 是”面向连接”的。软状态就是可以有一段时间不同步，异步。 软状态，指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。 Eventual Consistency –最终一致性 最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。 亚马逊首席技术官Werner Vogels在于2008年发表的一篇文章中对最终一致性进行了非常详细的介绍。他认为最终一致性时一种特殊的弱一致性：系统能够保证在没有其他新的更新操作的情况下，数据最终一定能够达到一致的状态，因此所有客户端对系统的数据访问都能够获取到最新的值。同时，在没有发生故障的前提下，数据达到一致状态的时间延迟取决于网络延迟，系统负载和数据复制方案设计等因素。 总的来说，BASE理论面向的是大型高可用可扩展的分布式系统，和传统事务的ACID【原子性（atomicity，或称不可分割性）、一致性（consistency）、隔离性（isolation，又称独立性）、持久性（durability）】特性是相反的，它完全不同于ACID的强一致性模型，而是提出通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。但同时，在实际的分布式场景中，不同业务单元和组件对数据一致性的要求是不同的，因此在具体的分布式系统架构设计过程中，ACID特性与BASE理论往往又会结合在一起使用。 http://www.frankyang.cn/2017/09/05/cap-base/]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>BlockChain</tag>
        <tag>Distributed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux进程状态转换图]]></title>
    <url>%2F2017%2F09%2F04%2FLinux%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[Linux进程状态Linux内核中的进程状态 ◆运行状态（TASK_RUNNING） 指正在被CPU运行或者就绪的状态。这样的进程被成为runnning进程。运行态的进程可以分为3种情况：内核运行态、用户运行态、就绪态。 ◆可中断睡眠状态（TASK_INTERRUPTIBLE） 处于等待状态中的进程，一旦被该进程等待的资源被释放，那么该进程就会进入运行状态。 ◆不可中断睡眠状态（TASK_UNINTERRUPTIBLE） 该状态的进程只能用wake_up()函数唤醒。 ◆暂停状态（TASK_STOPPED） 当进程收到信号SIGSTOP、SIGTSTP、SIGTTIN或SIGTTOU时就会进入暂停状态。可向其发送SIGCONT信号让进程转换到可运行状态。 ◆僵死状态（TASK_ZOMBIE） 当进程已经终止运行，但是父进程还没有询问其状态的情况。 http://www.frankyang.cn/2017/05/13/linux-jin-cheng-zhuang-tai/]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Process</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[密码学hash函数-SHA256-512]]></title>
    <url>%2F2017%2F09%2F04%2F%E5%AF%86%E7%A0%81%E5%AD%A6hash%E5%87%BD%E6%95%B0-SHA256-512%2F</url>
    <content type="text"><![CDATA[Hash函数又称哈希函数、散列函数、杂凑函数。它是一种单向密码体制，即从一个从明文到密文的不可逆映射，只有加密过程，没有解密过程。Hash函数H将可变长度的数据块M作为输入，产生固定长度的Hash值h=H(M)。在安全应用中使用的Hash函数称为密码学Hash函数。（单向性）、（抗碰撞性） 弱抗碰撞性：给定一个消息M，要找到另一个消息M’，使得H(M)=H(M’)很难。强抗碰撞性：要找到两个随机明文M和M’，使得H(M)=H(M’)很难。 Hash函数特点： 易压缩 易计算 单向性 抗碰撞性 高灵敏性 密码学Hash函数的应用范围消息认证消息认证是用来验证消息完整性的一种机制或服务。消息认证确保收到的数据确实和发送时的一样（即没有修改、插入、删除或重放）。当Hash函数用于提供消息认证功能时，Hash函数值通常称为消息摘要。 数字签名在进行数字签名过程中使用用户的私钥加密消息的Hash值，其他任何知道该用户公钥的人都能够通过数字签名来验证消息的完整性。 其他应用单向口令文件。入侵检测。病毒检测。构建随机函数（PRF）或用做伪随机数发生器（PRNG） 安全Hash算法（SHA）安全散列算法SHA（Secure Hash Algorithm）是美国国家安全局 （NSA） 设计，美国国家标准与技术研究院（NIST） 发布的一系列密码散列函数，包括 SHA-1、SHA-224、SHA-256、SHA-384 和 SHA-512 等变体。主要适用于数字签名标准（DigitalSignature Standard DSS）里面定义的数字签名算法（Digital Signature Algorithm DSA）。 SHA-1SHA-1产生160位的Hash值。SHA1始终把消息当成一个位（bit）字符串来处理。 SHA-2Hash值长度依次为256位、384位和512位，分别称为SHA-256、SHA-384和SHA-512，这些算法统称为SHA-2。SHA-2同SHA-1类似，都使用同样的迭代结构和同样的模算术运算与二元逻辑操作。 SHA-1 SHA-224 SHA-256 SHA-384 SHA-512 消息摘要长度 160 224 256 384 512 消息长度 &lt; 2^64 &lt; 2^64 &lt; 2^64 &lt; 2^128 &lt; 2^128 分组长度 512 512 512 1024 1024 字长度 32 32 32 64 64 步骤数 80 64 64 80 80 SHA-256算法SHA-256算法的输入是最大长度小于2^64 位的消息，输出是256位的消息摘要，输入消息以512位的分组为单位进行处理。步骤如下（1）消息填充 添加一个“1”和若干个“0”使其长度模512与448同余（即长度≡448(mod 512)）.在消息后附加64位的长度块，其值为填充前消息的长度。从而产生长度为512整数倍的消息分组，填充后消息的长度最多为2^64位。 （2）初始化链接变量 链接变量的中间结果和最终结果存储于256位的缓冲区中，缓冲区用8个32位的寄存器A、B、C、D、E、F、G和H表示，输出仍放在缓冲区以代替旧的A、B、C、D、E、F、G、H。首先要对链接变量进行初始化，初始链接变量存储于8个寄存器A、B、C、D、E、F、G和H中：A = 0x6a09e667 E = 0x510e527fB = 0xbb67ae85 F = 0x9b05688cC = 0x3c6ef372 G = 0x1f83d9abD = 0xa54ff53a H = 0x5be0cd19初始链接变量是取自前8个素数（2、3、5、7、11、13、17、19）的平方根的小数部分其二级制表示的前32位。 （3）处理主循环模块 消息块是以512位分组为单位进行处理的，要进行64步循环操作（如图）。每一轮的输入均为当前处理的消息分组和得到的上一轮输出的256位缓冲区A、B、C、D、E、F、G、H的值。每一步中均采用了不同的消息字和常数。 （4）得出最终的Hash值 所有512位的消息块分组都处理完以后，最后一个分组处理后得到的结果即为最终输出的256位的消息摘要。 步函数是SHA-256中最为重要的函数，也是SHA-256中最关键的部件。其运算过程如下图：每一步都会生成两个临时变量，即T1、T2：$$T_1=\Sigma_1(E)+Ch(E,F,G)+H+W_t+K_t$$$$T_2=\Sigma_0(A)+Maj(A,B,C) mod 2^{32}$$根据T1、T2的值，对寄存器A、E进行更新。A、B、C、D、E、F、G的输入值则一次赋值给B、C、D、F、G、H。$A=(T_1+T_2) mod 2^{32}$ $E=(D+T_2) mod 2^{32}$其中$Ch(E,F,G) = (E\wedge F)⊕(\overline{E}\wedge G)$$Maj(A,B,C) = (A\wedge B)\bigoplus (A\wedge C)\bigoplus (B\wedge C)$$\Sigma_0(A) = ROTR^{2}(A)\bigoplus ROTR^{13}(A)\bigoplus ROTR^{22}(A)$$\Sigma_1(E) = ROTR^{6}(E)\bigoplus ROTR^{11}(E)\bigoplus ROTR^{25}(E)$且ROTR^n (E)表示对32位的变量x循环右移n位。Kt的获取方法是取前64个素数（2，3，5，7……）立方根的小数部分，将其转换为二进制，然后取这64个数的前64位作为Kt。其作用是提供了64位随机串集合以消除输入数据里的任何规则性。对于每个输入分组导出的消息分组Wt，前16个消息字Wt（0&lt;=t&lt;=15）直接按照消息输入分组对应的16个32位字，其他的则按照如下公式来计算得出：$$W_{t} = W_{t-16} + \sigma 0(W{t-15}) + W_{t-7} + \sigma 1(W{t-2}) , 16\leqslant t\leqslant 63$$其中：$\sigma _0(x) = ROTR^{7}(x) \bigoplus ROTR^{18}(x) \bigoplus SHR^3(x)$$\sigma _1(x) = ROTR^{17}(x) \bigoplus ROTR^{19}(x) \bigoplus SHR^{10}(x)$式中，$SHR^{10}(x)$表示32位的变量x右移n位，其导出方法如图： SHA-512逻辑算法的输入时最大长度小于2^128 位的消息，输出是512位的消息摘要，输入消息1024位的分组为单位进行处理。步骤1：附加填充位 填充消息使其长度模1024与896同余（即长度≡896(mod 1024)），即使消息已经满足上述长度要求，仍然需要进行填充，因此填充位数在1~1024之间，填充由一个1和后续的0组成。 步骤2：附加长度 在消息后附加一个128位的块，将其视为128位的无符号整数（最高有效字节在前），它包含填充前消息的长度。 前两步的结果产生了一个长度为1024整数倍的消息。 步骤3：初始化Hash缓冲区 Hash函数的中间结果和最终结果保存于512位的缓冲区中，缓冲区用8个64位的寄存器（a,b,c,d,e,f,g,h）表示，并将这些寄存器初始化为下列64位的整数（十六进制值）：a = 6A09E667F3BCC908 e = 510E527FADE682D1b = BB67AE8584CAA73B f = 9B05688C2B3E6C1Fc = 3C6EF372FE94F82B g = 1F83D9ABFB41Bd6Bd = A54FF53A5F1D36F1 h = 5BE0CD19137E2179这些值以高位在前格式存储，也就是说，字的最高有效字节存于低地址字节位置（最左面）。这些字的获取方式如下：前8个素数取平方根，取小数部分的前64位。 步骤4：以1024位的分组（128个字节）为单位处理消息 算法的核心是具有80轮运算的模块。每一轮都把512位缓存区的值abcdefgh作为输入，并更新缓冲区的值。第一轮时，缓冲区里的值是中间值Hi-1。每一轮，如第t轮，使用一个64位的值Wt，该值由当前被处理的1024位消息分组Mi导出，导出算法是下面将要讨论的消息扩展算法（如下图）。每一轮还将使用附加的常数Kt，其中0&lt;=t&lt;=79，用来使每轮的运算不同。这些常数提供了64位随机串集合，可以初步消除输入数据里的统计规律。第80轮的输出和第一轮的输入Hi-1相加产生Hi。缓冲区的8个字和Hi-1中对应的字分别进行模2^64的加法运算。 步骤5：输出 所有的N个1024位分组都处理完以后，从第N阶段输出的是512位的消息摘要。 总结SHA-512的运算如下：H0 = IVHi = SUM64(Hi-1, abcdefghi)MD = HN其中，IV为第三步里中定义的abcdefgh缓冲区的初始值；abcdefghi为第i个消息分组处理的最后一轮的输出；N为消息（包括填充和长度域）中的分组数；SUM64为对输入对中的每个字进行独立的模2^64加；MD为最后的消息摘要值。 http://www.frankyang.cn/2017/09/02/mi-ma-xuehash-han-shusha256512/]]></content>
      <categories>
        <category>Cryptography</category>
      </categories>
      <tags>
        <tag>Cryptography</tag>
        <tag>hash</tag>
        <tag>SHA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据处理-Bitmap]]></title>
    <url>%2F2017%2F09%2F04%2F%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86-Bitmap%2F</url>
    <content type="text"><![CDATA[MapReduce是一种编程模型，用于大规模数据集（大于1TB）的并行运算。概念”Map（映射）”和”Reduce（归约）” Bit-map空间压缩和快速排序去重1. Bit-map的基本思想 32位机器上，对于一个整型数，比如int a=1 在内存中占32bit位，这是为了方便计算机的运算。但是对于某些应用场景而言，这属于一种巨大的浪费，因为我们可以用对应的32bit位对应存储十进制的0-31个数，而这就是Bit-map的基本思想。Bit-map算法利用这种思想处理大量数据的排序、查询以及去重。 Bitmap在用户群做交集和并集运算的时候也有极大的便利。 2. Bit-map应用之快速排序 假设我们要对0-7内的5个元素(4,7,2,5,3)排序（这里假设这些元素没有重复）,我们就可以采用Bit-map的方法来达到排序的目的。要表示8个数，我们就只需要8个Bit（1Bytes），首先我们开辟1Byte的空间，将这些空间的所有Bit位都置为0， 对应位设置为1: 遍历一遍Bit区域，将该位是一的位的编号输出（2，3，4，5，7），这样就达到了排序的目的，时间复杂度O(n)。 优点： 运算效率高，不需要进行比较和移位； 占用内存少，比如N=10000000；只需占用内存为N/8=1250000Byte=1.25M。 缺点： 所有的数据不能重复。即不可对重复的数据进行排序和查找。 3. Bit-map应用之快速去重 2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。 首先，根据“内存空间不足以容纳这2.5亿个整数”我们可以快速的联想到Bit-map。下边关键的问题就是怎么设计我们的Bit-map来表示这2.5亿个数字的状态了。其实这个问题很简单，一个数字的状态只有三种，分别为不存在，只有一个，有重复。因此，我们只需要2bits就可以对一个数字的状态进行存储了，假设我们设定一个数字不存在为00，存在一次01，存在两次及其以上为11。那我们大概需要存储空间几十兆左右。 接下来的任务就是遍历一次这2.5亿个数字，如果对应的状态位为00，则将其变为01；如果对应的状态位为01，则将其变为11；如果为11，,对应的转态位保持不变。 最后，我们将状态位为01的进行统计，就得到了不重复的数字个数，时间复杂度为O(n)。 4. Bit-map应用之快速查询 同样，我们利用Bit-map也可以进行快速查询，这种情况下对于一个数字只需要一个bit位就可以了，0表示不存在，1表示存在。假设上述的题目改为，如何快速判断一个数字是够存在于上述的2.5亿个数字集合中。 同之前一样，首先我们先对所有的数字进行一次遍历，然后将相应的转态位改为1。遍历完以后就是查询，由于我们的Bit-map采取的是连续存储（整型数组形式，一个数组元素对应32bits），我们实际上是采用了一种分桶的思想。一个数组元素可以存储32个状态位，那将待查询的数字除以32，定位到对应的数组元素（桶），然后再求余（%32），就可以定位到相应的状态位。如果为1，则代表改数字存在；否则，该数字不存在。 5. Bit-map扩展——Bloom Filter(布隆过滤器) 当一个元素被加入集合中时,通过k各散列函数将这个元素映射成一个位数组中的k个点,并将这k个点全部置为1. 有一定的误判率–在判断一个元素是否属于某个集合时,有可能会把不属于这个集合的元素误判为属于这个集合.因此,它不适合那些”零误判”的应用场合.在能容忍低误判的应用场景下,布隆过滤器通过极少的误判换区了存储空间的极大节省. Bloom Filter使用k个相互独立的哈希函数（Hash Function），它们分别将集合中的每个元素映射到{1,…,m}的范围中。对任意一个元素x，第i个哈希函数映射的位置hi(x)就会被置为1（1≤i≤k）。注：如果一个位置多次被置为1，那么只有第一次会起作用，后面几次将没有任何效果。在判断y是否属于这个集合时，对y应用k次哈希函数，若所有hi(y)的位置都是1（1≤i≤k），就认为y是集合中的元素，否则就认为y不是集合中的元素。 6. 总结 使用Bit-map的思想，我们可以将存储空间进行压缩，而且可以对数字进行快速排序、去重和查询的操作。Bloom Fliter是Bit-map思想的一种扩展，它可以在允许低错误率的场景下，大大地进行空间压缩，是一种拿错误率换取空间的数据结构。 7. 应用 适用范围：可进行数据的快速查找，判重，删除，一般来说数据范围是int的10倍以下 基本原理及要点：使用bit数组来表示某些元素是否存在，比如8位电话号码 扩展：bloom filter可以看做是对bit-map的扩展 问题实例：1、已知某个文件内包含一些电话号码，每个号码为8位数字，统计不同号码的个数。 8位最多99 999 999，大概需要99m个bit，大概10几M字节的内存即可。 2、在2.5亿个整数中找出不重复的整数，内存不足以容纳这2.5亿个整数。 方案1：采用2-Bitmap（每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）进行，共需内存2^32*2bit=1GB内存，还可以接受。然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所描完事后，查看bitmap，把对应位是01的整数输出即可。 http://www.frankyang.cn/2017/08/21/da-shu-ju-chu-libitmap/]]></content>
      <categories>
        <category>BigData</category>
      </categories>
      <tags>
        <tag>Bitmap</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[几种垃圾回收GC概述]]></title>
    <url>%2F2017%2F09%2F04%2F%E5%87%A0%E7%A7%8D%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6GC%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[垃圾回收机制引用计数回收器（Reference Counting Collector） 原理是在每个对象内部维护一个整数值，叫做这个对象的引用计数，当对象被引用时引用计数加一，当对象不被引用时引用计数减一。当引用计数为 0 时，自动销毁对象。 目前引用计数法主要用在 c++ 标准库的 std::shared_ptr 、微软的 COM 、Objective-C 和 PHP 中。 计数器表示资源（内存中的对象）的使用次数，当计数器变成零的时候就可以将该资源销毁。在向已有的系统添加垃圾回收器时，开发人员通常会选择计数回收器，因为这种方式最容易与已有的资源管理器和代码集成在一起。 不过引用计数算法存在很多问题。最大的一个问题是，它无法解决循环引用问题。 循环引用是指对象 A 和对象 B 互相持有对方的引用。这样两个对象的引用计数都不是 0 ，因此永远不能被收集，造成内存泄露。除此之外，引用计数需要额外的开销。 虽然现代CPU的运算能力很强，但内存并不快，而计数器的运算需要频繁使用内存。因为计数器需要不断被更新，所以它们不是只读的，而且不能保证线程安全。 引用计数器算法是一种摊销算法（将开销分摊给了程序），不过它是偶然性的摊销，无法保证响应时间。例如，假设程序正在处理一个很大的树结构，最后一个使用这个树的程序会触发销毁操作，根据墨菲定律，其延迟会比期望的要高。 标记清除回收器（Mark Sweep Collector） 标记清除回收算法解决了一些在引用计数算法中存在的问题。它解决了循环引用问题，而且开销要小得多，因为它不需要维护计数器。 这个算法分为两步，标记和清除。 1. 标记：从程序的根节点开始， 递归地 遍历所有对象，将能遍历到的对象打上标记。 2. 清除：讲所有未标记的的对象当作垃圾销毁。 不过，它无法立即检测到垃圾。这个算法还有一个缺陷，就是人们常常说的 STW 问题（Stop The World）。因为算法在标记时必须暂停整个程序，否则其他线程的代码可能会改变对象状态，从而可能把不应该回收的对象当做垃圾收集掉。 标记清除算法有更高的一致性要求，而且难以将其集成到已有的系统中。在标记阶段，回收器要求遍历所有的存活对象，包括封装在对象里的数据。如果某个对象不支持回收器的遍历访问，那么使用这种回收器就会存在风险。 复制回收器（Copying Collector） 节点复制也是基于追踪的算法。其将整个堆等分为两个半区（semi-space），一个包含现有数据，另一个包含已被废弃的数据。节点复制式垃圾收集从切换（flip）两个半区的角色开始，然后收集器在老的半区，也就是 Fromspace 中遍历存活的数据结构，在第一次访问某个单元时把它复制到新半区，也就是 Tospace 中去。在 Fromspace 中所有存活单元都被访问过之后，收集器在 Tospace 中建立一个存活数据结构的副本，用户程序可以重新开始运行了。 优点 所有存活的数据结构都缩并地排列在 Tospace 的底部，这样就不会存在内存碎片的问题。 获取新内存可以简单地通过递增自由空间指针来实现。 缺点 内存得不到充分利用，总有一半的内存空间处于浪费状态。 Copying算法的效率跟存活对象的数目多少有很大的关系，如果存活对象很多，那么Copying算法的效率将会大大降低。 标记整理回收器（Mark Compact Collector） 为了解决Copying算法的缺陷，充分利用内存空间，提出了Mark-Compact算法。该算法标记阶段和Mark-Sweep一样，但是在完成标记之后，它不是直接清理可回收对象，而是将存活对象都向一端移动，然后清理掉端边界以外的内存。 标记整理算法清理内存的方式不是通过清除，而是将对象移动到空余的内存空间。对象总是以不变的次序存留在内存里，先分配到内存的对象总处于较低的内存段，不过因为经过移动，对象间的内存间隙被消除。 新创建的对象总是处于内存的高段。这种内存分配器被称为“bump”，类似于栈的分配，只是没有栈那样的大小限制。有些使用bump分配器的系统甚至不用调用栈来存储数据，它们直接在堆里分配调用帧，并把它们看成对象。 从理论上看，这种回收算法的另一个优势在于，程序具有了更好的内存访问模型，这种模型对现代硬件的内存缓存更加友好。不过，相比其他算法，我们很难直观地感受到这种优势，因为引用计数和标记清除算法里所使用的内存分配器虽然很复杂，但它们很健壮，很高效。 标记整理是一种复杂的算法，需要多次遍历所有分配到内存的对象。这种复杂性所带来的主要好处就是极低的内存开销。Oracle的Hotspot虚拟机使用了多种垃圾回收算法。 三色标记法三色标记算法是对标记阶段的改进，原理如下： 1. 起初所有对象都是白色。 2. 从根出发扫描所有可达对象，标记为灰色，放入待处理队列。 3. 从队列取出灰色对象，将其引用对象标记为灰色放入队列，自身标记为黑色。 4. 重复 3，直到灰色对象队列为空。此时白色对象即为垃圾，进行回收。 这个算法可以实现 “on-the-fly”，也就是在程序执行的同时进行收集，并不需要暂停整个程序。但是也会有一个缺陷，可能程序中的垃圾产生的速度会大于垃圾收集的速度，这样会导致程序中的垃圾越来越多无法被收集掉。 分代收集 分代收集也是传统 Mark-Sweep 的一个改进。这个算法是基于一个经验：绝大多数对象的生命周期都很短。所以按照对象的生命周期长短来进行分代。 一般 GC 都会分三代，在 java 中称之为新生代（Young Generation）、年老代（Tenured Generation）和永久代（Permanent Generation）；在 .NET 中称之为第 0 代、第 1 代和第2代。 原理如下： 1. 新对象放入第 0 代 2. 当内存用量超过一个较小的阈值时，触发 0 代收集 3. 第 0 代幸存的对象（未被收集）放入第 1 代 4. 只有当内存用量超过一个较高的阈值时，才会触发 1 代收集 5. 2 代同理 因为 0 代中的对象十分少，所以每次收集时遍历都会非常快（比 1 代收集快几个数量级）。只有内存消耗过于大的时候才会触发较慢的 1 代和 2 代收集。 因此，分代收集是目前比较好的垃圾回收方式。使用的语言（平台）有 jvm、.NET 。 基于追踪的垃圾回收算法（标记-清扫、节点复制）一个主要问题是在生命周期较长的对象上浪费时间（长生命周期的对象是不需要频繁扫描的）。同时，内存分配存在这么一个事实 “most object die young”。基于这两点，分代垃圾回收算法将对象按生命周期长短存放到堆上的两个（或者更多）区域，这些区域就是分代（generation）。对于新生代的区域的垃圾回收频率要明显高于老年代区域。 分配对象的时候从新生代里面分配，如果后面发现对象的生命周期较长，则将其移到老年代，这个过程叫做 promote。随着不断 promote，最后新生代的大小在整个堆的占用比例不会特别大。收集的时候集中主要精力在新生代就会相对来说效率更高，STW 时间也会更短。 目前大部分垃圾收集器对于新生代都采取Copying算法，因为新生代中每次垃圾回收都要回收大部分对象，也就是说需要复制的操作次数较少，但是实际中并不是按照1：1的比例来划分新生代的空间的，一般来说是将新生代划分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden空间和其中的一块Survivor空间，当进行回收时，将Eden和Survivor中还存活的对象复制到另一块Survivor空间中，然后清理掉Eden和刚才使用过的Survivor空间。 而由于老年代的特点是每次回收都只回收少量对象，一般使用的是Mark-Compact算法。 注意，在堆区之外还有一个代就是永久代（Permanet Generation），它用来存储class类、常量、方法描述等。对永久代的回收主要回收两部分内容：废弃常量和无用的类。 优点性能更优。 缺点实现复杂 http://www.frankyang.cn/2017/08/30/gc/]]></content>
      <categories>
        <category>GC</category>
      </categories>
      <tags>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[什么是隔离见证？简单介绍隔离见证]]></title>
    <url>%2F2017%2F07%2F24%2F%E4%BB%80%E4%B9%88%E6%98%AF%E9%9A%94%E7%A6%BB%E8%A7%81%E8%AF%81%EF%BC%9F%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D%E9%9A%94%E7%A6%BB%E8%A7%81%E8%AF%81-%E7%B4%AB%E9%AD%94%E6%88%92%2F</url>
    <content type="text"><![CDATA[每一个比特币交易，都可以分为两部分。第一部分是转账记录，第二部分是用来证明这个交易合法性（主要是签名）的。第一部分可称为“交易状态”，第二部分就是所谓的见证（witness）。如果你只关心每个账户的余额，那么转账记录就已经足够了。只有部分人（主要是矿工）才有必要取得交易见证。(交易信息就是谁给谁在什么时间转了多少钱。见证信息就是哪个节点在什么时间验证交易信息的可靠性。) 中本聪在设计比特币的时候直接把这两个信息直接放在了区块内，所以一个区块就承载不了更多的交易信息，如果隔离了“见证信息”，那么区块链只记录交易信息，那么一个区块可承载的交易更多交易。中本聪设计比特币时，并没有把两部分资料分开处理，因此导致交易ID的计算混合了交易和见证。因为见证本身包括签名，而签名不可能对其自身进行签名，因此见证可以由任何人在未得到交易双方同意的情况下进行改变，造成所谓的交易可塑性（malleability）。在交易发出后、确认前，交易ID可以被任意更改，因此基于未确认交易的交易是绝对不安全的。在2014年就曾有人利用这个漏洞大规模攻击比特币网络。 比特币核心开发员Pieter Wuille在2015年12月于香港提出的隔离见证（Segregated Witness，以下简称SW）软分叉解决了这个问题。SW用户在交易时，会把比特币传送到有别于传统的地址。当要使用这些比特币的时候，其签名（即见证）并不会记录为交易ID的一部分，而是进行另外处理。也就是说，交易ID完全是由交易状态来决定的，不会受见证部分的影响。 部分开发者认为比特币的设计有缺陷，在数据结构方面，它把必要的交易信息（输入和输出）和“没那么必要”的交易信息（见证）放在一起打包，这造成了一系列问题，比如“交易可塑性”、交易签名过程复杂、还有存储空间“浪费”。隔离见证是对整个设计缺陷的一个修改方案，原理说起来挺简单，它允许交易把没那么必要的“见证”部分“隔离”在区块外面，这就是隔离见证的意思了。目前人们主要关注的是存储空间浪费，因为现在比特币交易量太大，区块空间不够用，大量交易堆积。隔离见证的设计减少了每个交易脚本在区块内的体积，这相当于区块空间扩容，同时降低了数据传输和验证造成的内存、带宽、CPU成本。 这做法有几个重要的结果: 可以用软分叉增加最大区块容量:因为旧有节点根本看不到这些被隔离的见证，即使真实的区块已超过1MB，它们仍会以为没有超过限制而会接受区块。在整场有关区块容量的辩论中，最大的难点就是硬分叉。SW可以提供约2MB的有效区块空间而没有任何硬分叉风险。 从此以后，只有发出交易的人才可以改变交易ID，没有任何第三方可以做到。如果是多重签名交易，就只有多名签署人同意才能改变交易ID。这可以保证一连串的未确认交易的有效性，是双向支付通道或闪电网络所必须的功能。有了双向支付通道或闪电网络，二人或多人之间就可以实际上进行无限次交易，而无需把大量零碎交易放在区块链，大为减低区块空间压力。 轻量钱包可以变得更轻量，因为它们无需再接收见证数据。 可以大幅改善签署结构。在区块链上，曾经有一个超过5000个输入的交易，因为签署设计缺憾，需要半分钟才能完成检查。在建议中的SW软分叉会把这个问题解决掉。 http://www.frankyang.cn/2017/07/24/segregated-witness/]]></content>
      <categories>
        <category>BlockChain</category>
      </categories>
      <tags>
        <tag>隔离见证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程死锁及解决办法]]></title>
    <url>%2F2017%2F06%2F25%2F%E8%BF%9B%E7%A8%8B%E6%AD%BB%E9%94%81%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95-%E7%B4%AB%E9%AD%94%E6%88%92%2F</url>
    <content type="text"><![CDATA[【摘要】进程死锁及解决办法一、要点提示（1） 掌握死锁的概念和产生死锁的根本原因。（2） 理解产生死锁的必要条件–以下四个条件同时具备：互斥条件、不可抢占条件、占有且申请条件、循环等待条件。（3） 记住解决死锁的一般方法，掌握死锁的预防和死锁的避免二者的基本思想。（4） 掌握死锁的预防策略中… 阅读全文 http://www.frankyang.cn/2017/06/25/lock/]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Process</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何实现守护进程？]]></title>
    <url>%2F2017%2F05%2F25%2F%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%AE%88%E6%8A%A4%E8%BF%9B%E7%A8%8B%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[守护进程（Daemon）是运行在后台的一种特殊进程。它独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件。守护进程是一种很有用的进程。 1、守护进程最重要的特性是后台运行。2、守护进程必须与其运行前的环境隔离开来。这些环境包括未关闭的文件描述符，控制终端，会话和进程组，工作目录以及文件创建掩模等。这些环境通常是守护进程从执行它的父进程（特别是shell）中继承下来的。3、守护进程的启动方式有其特殊之处。它可以在Linux系统启动时从启动脚本/etc/rc.d中启动，可以由作业规划进程crond启动，还可以由用户终端（shell）执行。 总之，除开这些特殊性以外，守护进程与普通进程基本上没有什么区别。因此，编写守护进程实际上是把一个普通进程按照上述的守护进程的特性改造成为守护进程。如果对进程有比较深入的认识就更容易理解和编程了。 守护进程之编程规则（1）首先要做的是调用umask将文件模式创建屏蔽字设置为0。 文件权限掩码：是指屏蔽掉文件权限中的对应位。例如，有个文件权限掩码是050，它就屏蔽了文件组拥有者的可读与可执行权限（对应二进制为，rwx, 101）。由于fork函数创建的子进程继承了父进程的文件权限掩码，这就给子进程使用文件带来了诸多的麻烦。因此，把文件权限掩码设置为0（即，不屏蔽任何权限），可以增强该守护进程的灵活性。设置文件权限掩码的函数是umask。通常的使用方法为umask(0)。 （2）调用fork，然后使父进程退出（exit）。if(pid=fork()) exit(0); （3）调用setsid以创建一个新会话，脱离控制终端和进程组。setsid函数作用：用于创建一个新的会话，并担任该会话组的组长。 调用setsid有3个作用：(a) 让进程摆脱原会话的控制；(b) 让进程摆脱原进程组的控制；(c) 让进程摆脱原控制终端的控制； setsid() 使用setsid函数的目的：由于创建守护进程的第一步调用了fork函数来创建子进程再将父进程退出。由于在调用fork函数时，子进程拷贝了父进程的会话期、进程组、控制终端等，虽然父进程退出了，但会话期、进程组、控制终端等并没有改变，因此，这还不是真正意义上的独立开了。使用setsid函数后，能够使进程完全独立出来，从而摆脱其他进程的控制。 （4）将当前工作目录更改为根目录。#define NOFILE 256 for(i=0;i&lt;NOFILE;i++) close(i); （5）关闭不再需要的文件描述符。这使守护进程不再持有从其父进程继承来的某些文件描述符（父进程可能是shell进程，或某个其他进程）。 （6）某些守护进程打开/dev/null使其具有文件描述符0、1和2，这样，任何一个试图读标准输入、写标准输出和标准出错的库例程都不会产生任何效果。因为守护进程并不与终端设备相关联，所以不能在终端设备上显示其输出，也无处从交互式用户那里接受输入。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#include &lt;sys/types.h&gt;#include&lt;sys/stat.h&gt;#include&lt;sys/time.h&gt;#include&lt;sys/resource.h&gt;#include&lt;unistd.h&gt;#include&lt;fcntl.h&gt;#include&lt;stdlib.h&gt;#include&lt;syslog.h&gt; void daemonize(const char *cmd) &#123; int i, fd0, fd1, fd2; pid_t pid; struct rlimit rl; struct sigaction sa; umask(0); // Clear file creation mask. if (getrlimit(RLIMIT_NOFILE, &amp;rl) &lt; 0) &#123; // Get maximum number of file descriptors. err_quit(&quot;%s: can&apos;t get file limit&quot;, cmd); &#125; if ((pid = fork()) &lt; 0) &#123; //这一步fork保证进程不是进程组组长进程 err_quit(&quot;%s: can&apos;t fork&quot;, cmd); &#125; else if (pid != 0) &#123; /* parent */ exit(0); &#125; setsid(); // 创建一个回话，会话只包含子进程，且子进程是会话首进程 /* 会话首进程的退出会出发SIGHUP信号 默认此信号的操作会终止进程 */ sa.sa_handler = SIG_IGN; sigemptyset(&amp;sa.sa_mask); sa.sa_flags = 0; if (sigaction(SIGHUP, &amp;sa, NULL) &lt; 0) &#123; err_quit(&quot;%s: can&apos;t ignore SIGHUP&quot;, cmd); &#125; /* 再次创建子进程，退出父进程，保证守护进程不是会话首进程，这样open的时候就不会被分配终端 */ if ((pid = fork()) &lt; 0) &#123; err_quit(&quot;%s: can&apos;t fork&quot;, cmd); &#125; else if (pid != 0) &#123; /* parent */ exit(0); &#125; if (chdir(&quot;/&quot;) &lt; 0) &#123; // 改变当前工作路径为根目录 err_quit(&quot;%s: can&apos;t change directory to /&quot;, cmd); &#125; if (rl.rlim_max == RLIM_INFINITY) &#123; //关闭所有打开的文件描述符 rl.rlim_max = 1024; &#125; for (i = 0; i &lt; rl.rlim_max; i++) &#123; close(i); &#125; /* 因为前面关闭了所有的文件描述符，此时open返回的必定是最小的0，后面两次dup返回的依次是1、2， 也就完成了对标准输入、标准输出、标准错误重定向至/dev/null的操作 */ fd0 = open(&quot;/dev/null&quot;, O_RDWR); fd1 = dup(0); fd2 = dup(0); /* * Initialize the log file. */ openlog(cmd, LOG_CONS, LOG_DAEMON); if (fd0 != 0 || fd1 != 1 || fd2 != 2) &#123; syslog(LOG_ERR, &quot;unexpected file descriptors %d %d %d&quot;,fd0, fd1, fd2); exit(1); &#125; &#125; http://www.frankyang.cn/2017/05/25/daemon/]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Process</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ 4种强制类型转换]]></title>
    <url>%2F2017%2F05%2F10%2FC%2B%2B%204%E7%A7%8D%E5%BC%BA%E5%88%B6%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[C++的四种强制类型转换为：static_cast、const_cast、reinterpret_cast和dynamic_cast 类型转换的一般形式：cast-name(expression); static_cast任何具有明确定义的类型转换，只要不包含底层const，都可以使用static_cast； double slope = static_cast(j) / i; 注： 顶层const：表示指针本身是个常量。如：int const p； 底层const：表示指针所指的对象是一个常量。如：int const p； const_cast该运算符只能改变运算对象的底层const。 12345678910#include&lt;iostream&gt; using namespace std;int main() &#123; const char *pc=" HDU"; char *p=const_cast&lt;char *&gt;(pc); //正确， cout&lt;&lt;"hello"&lt;&lt;p&lt;&lt;endl; return 0; &#125; 注：此处只能用const_cast，而不能用static_cast； reinterpret_cast通常为运算对象的位模式提供较低层次上的重新解释。注： 1、在指针之间转换，将一个类型的指针转换为另一个类型的指针，无关类型； 2、将指针值转换为一个整型数,但不能用于非指针类型的转换。 dynamic_cast只用于对象的指针和引用，不能用于内置的基本数据类型的强制转换。使用dynamic_cast进行转换的，基类中一定要有虚函数，否则编译不通过。运行时类型识别，用于将基类的指针或引用安全地转换成派生类的指针或引用。 对指针进行dynamic_cast，失败返回null，成功返回正常cast后的对象指针；对引用进行dynamic_cast，失败抛出一个异常bad_cast，成功返回正常cast后的对象引用。 对于“向上转换”（即派生类指针或引用类型转换为其基类类型），无论是指针还是引用向上转换都是安全地。对于“向下转型”有两种情况： 1、基类指针所指对象是派生类类型的，这种转换是安全的； 2、基类指针所指对象为基类类型，在这种情况下dynamic_cast在运行时做检查，转换失败，返回结果为0； 在引用上，dynamic_cast依旧是常用于“安全的向下转型”。与指针一样，引用的向下转型也可以分为两种情况，与指针不同的是，并不存在空引用，所以引用的dynamic_cast检测失败时会抛出一个bad_cast异常。 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;class A&#123;public: virtual void f() &#123; cout &lt;&lt; "hello" &lt;&lt; endl; &#125;&#125;; class B: public A&#123;public: void f() &#123; cout &lt;&lt; "hello2" &lt;&lt; endl; &#125; &#125;;int main()&#123; A* a1=new B;//a1是A类型的指针指向一个B类型的对象 A* a2=new A;//a2是A类型的指针指向一个A类型的对象 B* b; b=dynamic_cast&lt;B*&gt;(a1); //结果为not null，向下转换成功，a1之前指向的就是B类型的对象，所以可以转换成B类型的指针。 if(b==NULL) cout&lt;&lt;"null"&lt;&lt;endl; else cout&lt;&lt;"not null"&lt;&lt;endl; b=dynamic_cast&lt;B*&gt;(a2);//结果为null，向下转换失败 if(b==NULL) cout&lt;&lt;"null"&lt;&lt;endl; else cout&lt;&lt;"not null"&lt;&lt;endl; return 0;&#125; 总结 基本类型转换用static_cast。 去const属性用const_cast。 不同类型的指针类型转换用reinterpreter_cast。 多态类之间的类型转换用daynamic_cast。 C++ 4种强制类型转换C++的四种强制类型转换为：static_cast、const_cast、reinterpret_cast和dynamic_cast 类型转换的一般形式：cast-name(expression); static_cast任何具有明确定义的类型转换，只要不包含底层const，都可以使用static_cast； double slope = static_cast(j) / i; 注： 顶层const：表示指针本身是个常量。如：int const p； 底层const：表示指针所指的对象是一个常量。如：int const p； const_cast该运算符只能改变运算对象的底层const。 12345678910#include&lt;iostream&gt; using namespace std;int main() &#123; const char *pc=" HDU"; char *p=const_cast&lt;char *&gt;(pc); //正确， cout&lt;&lt;"hello"&lt;&lt;p&lt;&lt;endl; return 0; &#125; 注：此处只能用const_cast，而不能用static_cast； reinterpret_cast通常为运算对象的位模式提供较低层次上的重新解释。注： 1、在指针之间转换，将一个类型的指针转换为另一个类型的指针，无关类型； 2、将指针值转换为一个整型数,但不能用于非指针类型的转换。 dynamic_cast只用于对象的指针和引用，不能用于内置的基本数据类型的强制转换。使用dynamic_cast进行转换的，基类中一定要有虚函数，否则编译不通过。运行时类型识别，用于将基类的指针或引用安全地转换成派生类的指针或引用。 对指针进行dynamic_cast，失败返回null，成功返回正常cast后的对象指针；对引用进行dynamic_cast，失败抛出一个异常bad_cast，成功返回正常cast后的对象引用。 对于“向上转换”（即派生类指针或引用类型转换为其基类类型），无论是指针还是引用向上转换都是安全地。对于“向下转型”有两种情况： 1、基类指针所指对象是派生类类型的，这种转换是安全的； 2、基类指针所指对象为基类类型，在这种情况下dynamic_cast在运行时做检查，转换失败，返回结果为0； 在引用上，dynamic_cast依旧是常用于“安全的向下转型”。与指针一样，引用的向下转型也可以分为两种情况，与指针不同的是，并不存在空引用，所以引用的dynamic_cast检测失败时会抛出一个bad_cast异常。 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;class A&#123;public: virtual void f() &#123; cout &lt;&lt; "hello" &lt;&lt; endl; &#125;&#125;; class B: public A&#123;public: void f() &#123; cout &lt;&lt; "hello2" &lt;&lt; endl; &#125; &#125;;int main()&#123; A* a1=new B;//a1是A类型的指针指向一个B类型的对象 A* a2=new A;//a2是A类型的指针指向一个A类型的对象 B* b; b=dynamic_cast&lt;B*&gt;(a1); //结果为not null，向下转换成功，a1之前指向的就是B类型的对象，所以可以转换成B类型的指针。 if(b==NULL) cout&lt;&lt;"null"&lt;&lt;endl; else cout&lt;&lt;"not null"&lt;&lt;endl; b=dynamic_cast&lt;B*&gt;(a2);//结果为null，向下转换失败 if(b==NULL) cout&lt;&lt;"null"&lt;&lt;endl; else cout&lt;&lt;"not null"&lt;&lt;endl; return 0;&#125; 总结 基本类型转换用static_cast。 去const属性用const_cast。 不同类型的指针类型转换用reinterpreter_cast。 多态类之间的类型转换用daynamic_cast。 http://www.frankyang.cn/2017/05/10/c-4%E7%A7%8D%E5%BC%BA%E5%88%B6%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2/]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>Cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP超时重传、滑动窗口、拥塞控制、快重传和快恢复]]></title>
    <url>%2F2017%2F05%2F08%2FTCP%E8%B6%85%E6%97%B6%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E3%80%81%E5%BF%AB%E9%87%8D%E4%BC%A0%E5%92%8C%E5%BF%AB%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[TCP超时重传 原理是在发送某一个数据以后就开启一个计时器，在一定时间内如果没有得到发送的数据报的ACK报文，那么就重新发送数据，直到发送成功为止。 影响超时重传机制协议效率的一个关键参数是重传超时时间（RTO，Retransmission TimeOut）。RTO的值被设置过大过小都会对协议造成不利影响。 （1）RTO设长了，重发就慢，没有效率，性能差。 （2）RTO设短了，重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。 连接往返时间（RTT，Round Trip Time），指发送端从发送TCP包开始到接收它的立即响应所消耗的时间。 TCP滑动窗口作用：（1）提供TCP的可靠性；（2）提供TCP的流控特性 TCP的滑动窗口的可靠性也是建立在“确认重传”基础上的。发送窗口只有收到对端对于本段发送窗口内字节的ACK确认，才会移动发送窗口的左边界。接收端可以根据自己的状况通告窗口大小，从而控制发送端的接收，进行流量控制。 TCP拥塞控制 拥塞控制是一个全局性的过程； 流量控制是点对点通信量的控制 TCP拥塞控制4个核心算法：慢开始（slow start）、拥塞避免（Congestion Avoidance）、快速重传（fast retransmit）、快速回复（fast recovery） 拥塞窗口（cwnd，congestion window），其大小取决于网络的拥塞程度，并且动态地在变化。 慢开始算法的思路就是，不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小。 为了防止cwnd增长过大引起网络拥塞，还需设置一个慢开始门限ssthresh状态变量。ssthresh的用法如下：当cwnd &lt; ssthresh时，使用慢开始算法。当cwnd &gt; ssthresh时，改用拥塞避免算法。当cwnd = ssthresh时，慢开始与拥塞避免算法任意。 拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送发的拥塞窗口cwnd加1，而不是加倍。 无论是在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞，就把慢开始门限设置为出现拥塞时的发送窗口大小的一半。然后把拥塞窗口设置为1，执行慢开始算法。如下图：拥塞控制的具体过程如下：（1）TCP连接初始化，将拥塞窗口设置为1（2）执行慢开始算法，cwnd按指数规律增长，直到cwnd=ssthresh时，开始执行拥塞避免算法，cwnd按线性规律增长（3）当网络发生拥塞，把ssthresh值更新为拥塞前ssthresh值的一半，cwnd重新设置为1，按照步骤（2）执行 快重传和快恢复 快速重传(Fast retransmit)要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方），而不要等到自己发送数据时捎带确认。 快重传算法规定，发送方只要一连收到3个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计数器时间到期。 快速恢复(Fast Recovery) （1）当发送方连续收到三个重复确认，就执行“乘法减小”算法，把慢开始门限ssthresh减半。这是为了预防网络发生拥塞。请注意：接下去不执行慢开始算法。 （2）由于发送方现在认为网络很可能没有发生拥塞，因此与慢开始不同之处是现在不执行慢开始算法（即拥塞窗口cwnd现在不设置为1），而是把cwnd值设置为慢开始门限ssthresh减半后的数值，然后开始执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。 发送方窗口的上限值 = Min [ rwnd, cwnd ] 当rwnd &lt; cwnd 时，是接收方的接收能力限制发送方窗口的最大值。 当cwnd &lt; rwnd 时，则是网络的拥塞限制发送方窗口的最大值。 http://www.frankyang.cn/2017/05/08/tcp1/]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP与HTTPS异同||HTTP1.0与HTTP1.1差别]]></title>
    <url>%2F2017%2F04%2F19%2FHTTP%E4%B8%8EHTTPS%E5%BC%82%E5%90%8C%3AHTTP1.0%E4%B8%8EHTTP1.1%E5%B7%AE%E5%88%AB%2F</url>
    <content type="text"><![CDATA[HTTP状态码 分类 解释 描述 1XX 信息 服务器收到请求，需要请求者继续执行操作 2XX 成功 操作被成功接收并处理 3XX 重定向 需要进一步的操作以完成请求 4XX 客户端错误 请求包含语法错误或无法完成请求 5XX 服务器错误 服务器在处理请求的过程中发生了错误 常见的状态码 状态代码 状态消息 描述 200 成功 处理请求无误 301 永久移动 内容已移动到位置头中指明的主机上 400 错误请求 服务器不能理解请求 403 禁止 服务器无权访问所请求的文件 404 未发现 服务器不能找到所请求的方法 501 未实现 服务器不支持请求的方法 505 HTTP版本不支持 服务器不支持请求的版本 HTTP与HTTPS一、HTTP和HTTPS的基本概念 HTTP：互联网上应用最为广泛的一种网络协议，是一个客户端和服务器端请求和应答的标准(TCP)，用于从WWW服务器传输超文本到本地浏览器的传输协议。 HTTP协议采用明文传输信息，存在信息窃听、信息篡改和信息劫持的风险，而协议TLS/SSL具有身份验证、信息加密和完整性校验的功能，可以避免此类问题发生。 HTTPS（Hyper Text Transfer over Secure Socket Layer基于安全套接字层的超文本传输协议 ）：是以安全为目标的HTTP通道，简单讲是HTTP的安全版（HTTPS = HTTP + SSL），即HTTP下加入SSL层，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL。 HTTPS协议作用 1. 建立一个信息安全通道，来保证数据传输的安全； 2. 另一种就是确认网站的真实性。 二、HTTPS和HTTP的区别主要如下： 1、https协议需要到CA申请证书，一般免费证书较少，因而需要一定费用。 2、http是超文本传输协议，信息是明文传输，https则是具有安全性的SSL加密传输协议。 3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。 4、http的连接很简单，是无状态的；HTTPS协议是由HTTP+SSL协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。 三、HTTPS加密过程?1.客户端发起HTTPS请求 用户在浏览器里输入一个https网址，然后连接到server的443端口。 2.服务端的配置 采用HTTPS协议的服务器必须要有一套数字证书，可以自己制作，也可以向组织申请。这套证书其实就是一对公钥和私钥。 3.传送证书 这个证书其实就是公钥，只是包含了很多信息，如证书的颁发机构，过期时间等等。 4.客户端解析证书 这部分工作是有客户端的TLS来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等等，如果发现异常，则会弹出一个警告框，提示证书存在问题。如果证书没有问题，那么就生成一个随即值。然后用证书对该随机值进行加密。 5.传送加密随机值 这部分传送的是用证书加密后的随机值，目的就是让服务端得到这个随机值，以后客户端和服务端的通信就可以通过这个随机值来进行加密解密了。 6.服务段解密信息 服务端用私钥解密后，得到了客户端传过来的随机值(私钥)，然后把内容通过该值进行对称加密。所谓对称加密就是，将信息和私钥通过某种算法混合在一起，这样除非知道私钥，不然无法获取内容，而正好客户端和服务端都知道这个私钥。 7.传输加密后的信息 这部分信息是服务段用私钥加密后的信息，可以在客户端被还原 8.客户端解密信息 客户端用之前生成的私钥解密服务段传过来的信息，于是获取了解密后的内容。整个过程第三方即使监听到了数据，也束手无策。 四、什么时候该使用 HTTPS? 缺点？银行网站、支付网关、购物网站、登录页、电子邮件以及一些企业部门的网站应该使用 HTTPS ####缺点（1）HTTPS协议握手阶段比较费时，会使页面的加载时间延长近50%，增加10%到20%的耗电； （2）HTTPS连接缓存不如HTTP高效，会增加数据开销和功耗，甚至已有的安全措施也会因此而受到影响； （3）SSL证书需要钱，功能越强大的证书费用越高，个人网站、小网站没有必要一般不会用。 HTTP1.0与HTTP1.11、HTTP 1.1支持长连接（Persistent Connection）和请求的流水线（Pipelining）处理 HTTP 1.0规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接，服务器不跟踪每个客户也不记录过去的请求。 HTTP 1.1支持持久连接，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。 HTTP 1.1还允许客户端不用等待上一次请求结果返回，就可以发出下一次请求，但服务器端必须按照接收到客户端请求的先后顺序依次回送响应结果，以保证客户端能够区分出每次请求的响应内容，这样也显著地减少了整个下载过程所需要的时间。 2、HTTP 1.1增加host字段 在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。 HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。此外，服务器应该接受以绝对路径标记的资源请求。 HTTP 1.1还提供了与身份认证、状态管理和Cache缓存等机制相关的请求头和响应头。 3、100(Continue) Status(节约带宽) HTTP/1.1加入了一个新的状态码100（Continue）。客户端事先发送一个只带头域的请求，如果服务器因为权限拒绝了请求，就回送响应码401（Unauthorized）；如果服务器接收此请求就回送响应码100，客户端就可以继续发送带实体的完整请求了。100 (Continue) 状态代码的使用，允许客户端在发request消息body之前先用request header试探一下server，看server要不要接收request body，再决定要不要发request body。 http://www.frankyang.cn/2017/04/19/http-https/]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>Http</tag>
        <tag>Https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP三次握手四次挥手]]></title>
    <url>%2F2017%2F04%2F18%2FTCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%2F</url>
    <content type="text"><![CDATA[TCP三次握手四次挥手 标志位缩写 全称 中文 SYN synchronous 建立联机 ACK acknowledgement 确认 PSH push 传送 FIN finish 结束 RST reset 重置 URG urgent 紧急 Seq Sequence number 顺序号码 ACK Acknowledge number 确认号码 状态名称 意义 LISTEN 侦听来自远方TCP端口的连接请求 SYN-SENT 在发送连接请求后等待匹配的连接请求 SYN-RECEIVED 在收到和发送一个连接请求后等待对连接请求的确认 ESTABLISHED 代表一个打开的连接，数据可以传送给用户 FIN-WAIT-1 等待远程TCP的连接中断请求，或先前的连接中断请求的确认 FIN-WAIT-2 从远程TCP等待连接中断请求 CLOSE-WAIT 等待从本地用户发来的连接中断请求 CLOSING 等待远程TCP对连接中断的确认 LAST-ACK 等待原来发向远程TCP的连接中断请求的确认 TIME-WAIT 等待足够的时间以确保远程TCP接收到连接中断请求的确认 CLOSED 没有任何连接状态 【注意】 在TIME_WAIT状态中，如果TCP client端最后一次发送的ACK丢失了，它将重新发送。TIME_WAIT状态中所需要的时间是依赖于实现方法的。典型的值为30秒、1分钟和2分钟。等待之后连接正式关闭，并且所有的资源(包括端口号)都被释放 根据TCP协议定义的3次握手断开连接规定,发起socket主动关闭的一方 socket将进入TIME_WAIT状态。TIME_WAIT状态将持续2个MSL(Max Segment Lifetime),在Windows下默认为4分钟，即240秒。TIME_WAIT状态下的socket不能被回收使用. 具体现象是对于一个处理大量短连接的服务器,如果是由服务器主动关闭客户端的连接，将导致服务器端存在大量的处于TIME_WAIT状态的socket， 甚至比处于Established状态下的socket多的多,严重影响服务器的处理能力，甚至耗尽可用的socket，停止服务。 【问题】为什么连接的时候是三次握手，不是两次呢？ &emsp;&emsp;现假定出现一种异常情况，即A发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间滞留了，以致延误到连接释放以后的某个时间才到达B。本来这是一个早已失效的报文段。但B收到此失效的连接请求报文段后，就误认为是A又发出一次新的连接请求。于是就向A发出确认报文段，同意建立连接。假定不采用三次握手，那么只要B发出确认，新连接就建立了。&emsp;&emsp;由于现在A并没有发出建立连接的请求，因此不会理睬B的确认，也不会向B发送数据。但B却以为新的运输连接已经建立了，并一直等待A发来数据，B的许多资源就这样白白浪费了。 【问题】关闭的时候却是四次握手？ 答：因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，”你发的FIN报文我收到了”。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。&emsp;&emsp;关闭连接时，当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，乙方也未必全部数据都发送给对方了，所以乙方可以立即close，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，乙方ACK和FIN一般都会分开发送。 【问题】为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？ 答：虽然按道理，四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是我们必须假象网络是不可靠的，有可以最后一个ACK丢失。所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。 【问题】主动发起关闭连接的操作的一方将达到TIME_WAIT状态，而且这个状态要保持Maximum Segment Lifetime的两倍时间。为什么要这样做而不是直接进入CLOSED状态？1.保证TCP协议的全双工连接能够可靠关闭 如果Client直接CLOSED了，那么由于IP协议的不可靠性或者是其它网络原因，导致Server没有收到Client最后回复的ACK。那么Server就会在超时之后继续发送FIN，此时由于Client已经CLOSED了，就找不到与重发的FIN对应的连接，最后Server就会收到RST而不是ACK，Server就会以为是连接错误把问题报告给高层。这样的情况虽然不会造成数据丢失，但是却导致TCP协议不符合可靠连接的要求。所以，Client不是直接进入CLOSED，而是要保持TIME_WAIT，当再次收到FIN的时候，能够保证对方收到ACK，最后正确的关闭连接。 2.保证这次连接的重复数据段从网络中消失 如果Client直接CLOSED，然后又再向Server发起一个新连接，我们不能保证这个新连接与刚关闭的连接的端口号是不同的。也就是说有可能新连接和老连接的端口号是相同的。一般来说不会发生什么问题，但是还是有特殊情况出现：假设新连接和已经关闭的老连接端口号是一样的，如果前一次连接的某些数据仍然滞留在网络中，这些延迟数据在建立新连接之后才到达Server，由于新连接和老连接的端口号是一样的，又因为TCP协议判断不同连接的依据是socket pair，于是，TCP协议就认为那个延迟的数据是属于新连接的，这样就和真正的新连接的数据包发生混淆了。所以TCP连接还要在TIME_WAIT状态等待2倍MSL，这样可以保证本次连接的所有数据都从网络中消失。 SYN攻击：&emsp;&emsp;在三次握手过程中，Server发送SYN-ACK之后，收到Client的ACK之前的TCP连接称为半连接（half-open connect），此时Server处于SYN_RCVD状态，当收到ACK后，Server转入ESTABLISHED状态。&emsp;&emsp;SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server回复确认包，并等待Client的确认，由于源地址是不存在的，因此，Server需要不断重发直至超时，这些伪造的SYN包将长时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络堵塞甚至系统瘫痪。&emsp;&emsp;SYN攻击时一种典型的DDOS攻击，检测SYN攻击的方式非常简单，即当Server上有大量半连接状态且源IP地址是随机的，则可以断定遭到SYN攻击了，使用如下命令可以让之现行： #netstat -nap | grep SYN_RECV http://www.frankyang.cn/2017/08/23/tcp-san-ci-wo-shou-si-ci-hui-shou/]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>Network</tag>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
</search>
